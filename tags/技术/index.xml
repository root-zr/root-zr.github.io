<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>技术 on Albert Wang</title>
    <link>https://root-zr.github.io/tags/%E6%8A%80%E6%9C%AF/</link>
    <description>Recent content in 技术 on Albert Wang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Feb 2025 13:39:37 +0800</lastBuildDate><atom:link href="https://root-zr.github.io/tags/%E6%8A%80%E6%9C%AF/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Consistency and Consensus | 一致性和共识</title>
      <link>https://root-zr.github.io/en/2025/02/06/consistency-and-consensus-%E4%B8%80%E8%87%B4%E6%80%A7%E5%92%8C%E5%85%B1%E8%AF%86/</link>
      <pubDate>Thu, 06 Feb 2025 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2025/02/06/consistency-and-consensus-%E4%B8%80%E8%87%B4%E6%80%A7%E5%92%8C%E5%85%B1%E8%AF%86/</guid>
      <description>这篇博客记录一下分布式系统中的几个比较容易让人混淆的概念。
一致性 在分布式系统中，一致性模型用于描述多个副本或节点之间的数据一致性程度。越强的一致性往往意味着越差的处理性能。根据选择一致性的强度不同，分为强一致性和弱一致性。
强一致性 (Strong Consistency) 强一致性要求所有操作按全局顺序执行，任何读取操作都能看到最新写入的数据。系统表现得像只有一个数据副本，所有操作按顺序执行。
想象这样一种场景：用户A向用户B转账100元。
强一致性要求转账完成后，用户A和用户B的账户余额必须立即更新，且任何查询操作都能看到最新的余额。如果用户B在转账后立即查询余额，一定会看到增加了100元的结果。
强一致性还分为顺序一致性和线性一致性。
  顺序一致性 (Sequential Consistency)：要求所有操作按某个全局顺序执行，且每个节点的操作顺序与程序顺序一致。不保证实时性，但保证所有节点看到相同的操作顺序。如果两个线程同时对一个共享变量进行操作。
线程1执行：x = 1，然后x = 2。线程2执行：x = 3，然后读取x的值。顺序一致性要求所有线程看到的操作顺序必须一致。例如，线程2可能看到操作顺序为x = 1 -&amp;gt; x = 3 -&amp;gt; x = 2，但所有线程必须看到相同的顺序。
  线性一致性 (Linearizability)：强一致性的特例，要求所有操作按全局顺序执行，且操作实时生效。任何读取操作都能看到之前所有写入的结果。在多个客户端尝试获取同一个锁的场景下，线性一致性要求锁的获取和释放操作必须按真实时间顺序生效。如果客户端A在时间点T1获取了锁，客户端B在时间点T2尝试获取锁（T2 &amp;gt; T1），那么客户端B必须看到锁已被A持有，直到A释放锁。系统表现得像只有一个锁服务，所有操作按真实时间顺序执行。操作按全局顺序执行，且实时生效。
  弱一致性 (Weak Consistency) 弱一致性不保证读取操作能看到最新写入的数据，允许数据在一段时间内不一致，但最终会达到一致状态。
假如用户A发布了一条动态，用户B尝试查看这条动态。弱一致性允许用户B可能不会立即看到用户A的动态，因为系统可能存在延迟，数据还未同步到所有节点。用户B可能需要刷新几次页面，或者等待一段时间才能看到用户A的动态。
共识 共识算法是分布式系统中用于确保所有节点就某一状态或决策达成一致的机制。其核心目标是让系统在存在故障或网络延迟的情况下，仍能正常运行并保持一致。
一致性的概念比共识广泛，一致性指系统在某一时刻所有节点的数据状态相同，强调结果；共识指分布式系统中所有节点就某一状态或决策达成一致的过程，强调过程。</description>
    </item>
    
    <item>
      <title>Disaggregated Memory | 云计算之分解内存系统</title>
      <link>https://root-zr.github.io/en/2025/02/03/disaggregated-memory-%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B9%8B%E5%88%86%E8%A7%A3%E5%86%85%E5%AD%98%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Mon, 03 Feb 2025 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2025/02/03/disaggregated-memory-%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B9%8B%E5%88%86%E8%A7%A3%E5%86%85%E5%AD%98%E7%B3%BB%E7%BB%9F/</guid>
      <description>这篇博客主要介绍云计算中的分解内存系统。在分解内存系统中，计算节点和内存节点分别负责计算和存储。
分解内存系统 内存缓存系统是云服务的核心组件。然而，由于传统单体服务器中CPU与内存的紧耦合，现有缓存系统无法以资源高效且敏捷的方式弹性调整资源。为实现更好的弹性，人们将内存缓存系统移植到分解内存系统（Disaggregated Memory, DM）架构中，该架构将计算与内存资源解耦并支持灵活分配。分解内存系统将内存、存储和计算资源分离为独立的资源池，以实现高资源利用率、灵活的硬件可扩展性和高效的数据共享。采用支持RDMA的网络进行通信，RDMA具有高吞吐量（40-400 Gbps）、低延迟（几微秒）和绕过远程CPU/内核的特点。分解内存系统已成为许多应用的重要基础设施，包括数据库和内存键值（KV）存储。
索引 树结构和学习索引是两种广泛使用的有序KV存储结构，它们通过识别给定范围内的项来提供高效的范围查询性能。
基于树的结构 （例如 B+ 树）将数据存储在叶子节点中，并通过构建多级内部节点来搜索叶子。然而，当数据超出有限的本地缓存时，基于树的结构变得低效，必须进行多次网络往返时间（RTT）来检索内部节点。
学习索引在搜索速度和内存消耗方面相较于基于树的结构具有显著优势，这得益于易于使用且小尺寸的学习模型。具体来说，学习索引将数据搜索过程视为回归模型，通过近似排序键的累积分布函数（CDF）来记录所有数据的位置 。学习模型比树结构的内部节点节省了 2 到 4 个数量级的空间，这使得本地机器能够缓存整个索引结构，避免了多次 RTT 的惩罚，从而确定远程数据的位置。
XStore 提出了一个混合索引结构，即维护一个 B 树来处理修改，并本地缓存学习索引以进行远程数据访问。XStore 提供了高效的搜索性能，因为它仅需要一次 RTT 来访问静态工作负载。对于动态工作负载，XStore 通过在内存节点上修改 B 树来处理数据修改请求。同时，XStore 扩展过时的模型到较大的预测范围，以确保新插入的数据被包含在内。
然而，这种设计在解耦内存系统中变得低效，因为内存节点的计算资源有限，无法高效处理密集的修改请求。新模型未能及时重新训练，且由于模型扩展，过时的模型导致搜索远程数据时的准确性过低，无法在一次 RTT 内完成。因此，本地缓存变得无效，后续的数据请求通过经典的 RPC 转发到内存节点。由于内存节点的计算资源有限，整体性能显著下降。
上图展示了 ROLEX 的总体架构1。在内存池中，ROLEX 将所有数据存储为固定大小的叶节点（即数组），并基于这些数据构建一个与重训练解耦的学习索引。为了处理动态工作负载，计算节点直接修改远程叶节点，而无需重训练模型，因为我们将插入操作和重训练操作解耦。通过添加偏置和一些数据迁移约束，非重训练模型能够在插入新数据后正确识别所有数据。
缓存性能 在DM上构建弹性缓存系统面临两大挑战：
 绕过远程CPU的访问阻碍缓存算法执行：客户端通过远程直接内存访问（RDMA）直接操作数据，导致集中式热度监控失效，且维护缓存数据结构需多次高延迟远程访问。 资源动态调整影响缓存命中率：计算资源（客户端并发数）和内存资源（缓存容量）的变化会改变数据访问模式，使得固定缓存算法难以适应动态场景。  Ditto采用分布式自适应缓存策略，通过实时评估多个缓存算法的性能，动态切换至最佳适配算法以提升缓存命中率2。
上图展示了 Ditto 的整体架构。Ditto 采用哈希表组织内存池中存储的对象。该哈希表保存指向缓存对象地址的指针。遵循现有DM存储系统架构，应用程序运行于计算节点，每个应用程序通过本地子进程托管一个Ditto客户端。每个Ditto客户端在专用核心上运行多线程，应用程序通过本地共享内存与Ditto客户端通信，执行Get和Set操作。在此架构下，应用程序可通过增减分配给Ditto的线程数和CPU核心数自由扩缩计算资源。由于增减CPU核心时无需调整内存池的缓存容量，计算资源调整与缓存数据完全解耦。
Ditto通过两大核心机制实现DM上的缓存淘汰：
 以客户端为中心的缓存框架：通过为不同缓存算法生成多组淘汰候选，高效执行多种算法。 分布式自适应缓存策略：利用机器学习分析当前数据访问模式特征，选择性能最优的算法淘汰候选。    https://www.usenix.org/conference/fast23/presentation/li-pengfei&amp;#160;&amp;#x21a9;&amp;#xfe0e;
 Jiacheng Shen, Pengfei Zuo, Xuchuan Luo, Yuxin Su, Jiazhen Gu, Hao Feng, Yangfan Zhou, Michael Lyu, “Ditto: An Elastic and Adaptive Memory-Disaggregated Caching System”, Proceedings of the 29th ACM Symposium on Operating Systems Principles (SOSP), 2023.</description>
    </item>
    
    <item>
      <title>Elastic Block Storage | 云计算之块存储</title>
      <link>https://root-zr.github.io/en/2024/10/05/elastic-block-storage-%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B9%8B%E5%9D%97%E5%AD%98%E5%82%A8/</link>
      <pubDate>Sat, 05 Oct 2024 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2024/10/05/elastic-block-storage-%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B9%8B%E5%9D%97%E5%AD%98%E5%82%A8/</guid>
      <description>这篇博客主要从阿里巴巴的论文 “What&amp;rsquo;s the Story in EBS Glory: Evolutions and Lessons in Building Cloud Block Store” 来介绍云块存储。详细的内容可以参考 Fast2024 主页的演讲1。如果存在网络问题也可以从我本地连接下载，论文原文点击这里 ，PPT点击这里 。
阿里巴巴的云块存储从开始发展至今已经经过了多次迭代，从下面的时间线可以看出距离 2012 年的 EBS1 开始已经发展到了 EBSX 的版本。
BES1 在云计算的 IaaS 中，云厂商可以把计算资源和存储资源这些基础设施抽象成服务，对外以虚拟机的方式出售。云计算的客户只会感知到虚拟机提供的资源，但是在云计算厂商内部，虚拟机内的资源可以映射到不同的物理机上。计算和存储分离就是其中一种设计，通过将计算资源和存储资源放在不同的集群中，集群中间通过数据中心网络连接。这些设计也在微软的 Azure 和 Google 的数据中心中被采用。
块存储对外提供的是一种虚拟磁盘（Virtual Disk，VD），一台虚拟机可以挂载多个 VD。到目前我们云计算客户如果要使用存储资源，他们可以先购买不同容量的 VD，然后把 VD 挂载到自己的虚拟机中。事实上 EBS1 的设计也是如此，下图中计算集群中的 1 个 BlockClient 可以负责多个 VM，它们负责将 IO 请求转发到存储集群的 BlockServer 中。
BlockServer 本身是无状态的，这就需要构建 BlockManager 集群来管理 VD 的元数据，包括容量，快照版本等等。另外 VD 的逻辑块地址（LBA）被划分成一个个 64M 的块（chunk）。ChunkServer 就是用来处理这一个个的 chunk。同样地，也需要有 ChunkManager 来管理 chunk 的元数据。
这时一个 IO 从计算集群的 VM 发过来，BlockClient 会先从 BlockManager 找到该 IO 应该发给哪个 BlockServer ，收到 ACK 之后发到对应的 BlockServer，然后 BlockServer 从 ChunkManager 查到该请求应该发给哪个 ChunkServer ，最后在一层层返回 ACK 给 BlockClient，这样就完成了一次 IO。</description>
    </item>
    
    <item>
      <title>The Shortest Path of Graphs | 图的最短路问题3</title>
      <link>https://root-zr.github.io/en/2023/05/02/the-shortest-path-of-graphs-%E5%9B%BE%E7%9A%84%E6%9C%80%E7%9F%AD%E8%B7%AF%E9%97%AE%E9%A2%983/</link>
      <pubDate>Tue, 02 May 2023 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2023/05/02/the-shortest-path-of-graphs-%E5%9B%BE%E7%9A%84%E6%9C%80%E7%9F%AD%E8%B7%AF%E9%97%AE%E9%A2%983/</guid>
      <description>对于下面这个 3 * 3 的矩阵来说，如果我们想要从从左上角走到右下角，每次只能走一步，问怎么走距离最短。
假如现在有一个问题，对于下面这个 3 * 3 的矩阵来说，如果我们想要从从左上角走到右下角，每次只能走一步，问怎么走距离最短？
这个题目我们一般就直接采用 BFS 计算出结果，这样做无疑是最方便的。但是我们同样可以先构建图，然后再使用 dijkstra 算法来计算最小路径。上面的矩阵可以被表示为下面这样的一张图，
但是我们用邻接表表示这张图就稍微有点困难了，因为一般来说我们表示图的某一个节点一般是用一个数字 i （ 0 &amp;lt;= i &amp;lt; n） 来表示的，但是这回的顶点确是用（i， j）这一个点对来表示的。所以我们邻接表的数据结构用数组 + 链表就不太方便了，这时可以用 Map 来表示。
在 Java 语言的实现中一般是要用 HashMap，这时就要考虑可能出现哈希碰撞的情况，比较有效的一个办法是重写 hashCode 函数，如下图中的 Pair 对象。关于为什么要重写 hashCode 函数可以参考我这篇博客 。
class Pair { int x; int y; int distance; public Pair(int x, int y, int distance) { this.x = x; this.y = y; this.distance = distance; } public int hashCode() { return (x &amp;lt;&amp;lt; 16) | y; } public boolean equals(Object a) { Pair obj = (Pair)a; if (obj == null) { return false; } return this.</description>
    </item>
    
    <item>
      <title>The Shortest Path of Graphs | 图的最短路问题2</title>
      <link>https://root-zr.github.io/en/2023/04/22/the-shortest-path-of-graphs-%E5%9B%BE%E7%9A%84%E6%9C%80%E7%9F%AD%E8%B7%AF%E9%97%AE%E9%A2%982/</link>
      <pubDate>Sat, 22 Apr 2023 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2023/04/22/the-shortest-path-of-graphs-%E5%9B%BE%E7%9A%84%E6%9C%80%E7%9F%AD%E8%B7%AF%E9%97%AE%E9%A2%982/</guid>
      <description>在几个月前我总结了图最短路问题常用的几个算法以及实现 。但是随后我就发现了一个很大的问题，之前算法的实现都是采用的邻接矩阵，这种实现方式最大的问题就是太占用内存空间。假如一个稀疏图有 n 个顶点，m 条边（其中 m &amp;laquo; n)，在这种情况下用邻接矩阵来表示图需要的内存空间是$O(n^2)$，在一些算法题中 n 的数量往往会达到 $10^5$，而给定的内存范围是 $10^9$，这就导致临界矩阵往往不能用来做这些图的题目。如果采用邻接表来表示一个图只需要 $O(n + m)$ 的内存空间，所以下面我们用邻接表来实现Dijkstra 算法。
首先我们来构造图，代码如下。其中 n 表示有 n 个节点，并且节点的值为 0 ~ n - 1，edges 表示边的集合，edge[0]和edge[1]表示从 edge[0] 到 edge[1] 有边，edge[2] 表示这条边的权重。
 public int init(int n, int[][] edges) { ArrayList&amp;lt;Node&amp;gt;[] graph = new ArrayList[n]; for (int i = 0; i &amp;lt; n; i++) { graph[i] = new ArrayList&amp;lt;&amp;gt;(); } for (int[] edge : edges) { graph[edge[0]].add(new Node(edge[1], edge[2])); graph[edge[1]].</description>
    </item>
    
    <item>
      <title>Override equals and hashCode method in HashMap | Java使用HashMap需要重写equals和hashCode方法的场景</title>
      <link>https://root-zr.github.io/en/2023/04/21/override-equals-and-hashcode-method-in-hashmap-java%E4%BD%BF%E7%94%A8hashmap%E9%9C%80%E8%A6%81%E9%87%8D%E5%86%99equals%E5%92%8Chashcode%E6%96%B9%E6%B3%95%E7%9A%84%E5%9C%BA%E6%99%AF/</link>
      <pubDate>Fri, 21 Apr 2023 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2023/04/21/override-equals-and-hashcode-method-in-hashmap-java%E4%BD%BF%E7%94%A8hashmap%E9%9C%80%E8%A6%81%E9%87%8D%E5%86%99equals%E5%92%8Chashcode%E6%96%B9%E6%B3%95%E7%9A%84%E5%9C%BA%E6%99%AF/</guid>
      <description>当我们使用对象类型作为 HashMap 的 key的时候，我们往往希望两个对象里的某一个或者某几个成员变量相等，则这两个对象是相等的，而不是说采用 Java 默认的地址空间一致并且值也相等才表示两个对象相等。
假设我们有一个对象 Node表示一个点，它有两个成员变量 a 和 b
class Node { int a; // 表示从a到b int b; public Node(int a, int b) { this.a = a; this.b = b; } } 现在我们创建一个 HashMap，并且在 map 里存入点（1，1）然后我们获取点（1，1）对应的权重。
public class Test { public static void main(String[] args) { HashMap&amp;lt;Node, Integer&amp;gt; map = new HashMap&amp;lt;&amp;gt;(); Node node = new Node(1, 1); map.put(node, 2); System.out.println(map.get(new Node(1, 1))); } } 我们运行代码可以发现 map 返回的值是 null 而不是 2，这是因为我们在获取的时候又用 new 关键字创建了一个对象，然后在堆区开辟了一块新的内存空间，这导致这个“新的对象”之前并没有存在hash表里。</description>
    </item>
    
    <item>
      <title>The Shortest Path of Graphs | 图的最短路问题</title>
      <link>https://root-zr.github.io/en/2023/01/07/the-shortest-path-of-graphs-%E5%9B%BE%E7%9A%84%E6%9C%80%E7%9F%AD%E8%B7%AF%E9%97%AE%E9%A2%98/</link>
      <pubDate>Sat, 07 Jan 2023 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2023/01/07/the-shortest-path-of-graphs-%E5%9B%BE%E7%9A%84%E6%9C%80%E7%9F%AD%E8%B7%AF%E9%97%AE%E9%A2%98/</guid>
      <description>问题背景 假设我们有下面这张图，图中边的权重表示两点之间的距离。我们希望找到一条最短的路径从这张图的 A 点出发，最终走到 E 点，该怎样考虑这个问题呢？
这个问题很具有现实的意义，假设两点表示两个城市的距离，我们往往希望能够走最短距离的那条路到达目的地。而且这个问题也有一个隐含的条件，那就路的距离不可能为负数，所以我们可以考虑使用 Dijkstra 算法来进行求解。
Dijkstra 算法 Dijkstra 算法考虑对每一个点进行标号，每个点对应着两种状态（固定标号和临时标号，表示已经确定最短路径和尚未确定），一开始只有出发点的状态是已经确定最短路径的，然后会在迭代的时候去更新标号点，同时也会对每个点的最短路径进行更新。
图表模拟 下面我们先用图表的方式来进行模拟 Dijkstra 的求解过程。首先我们用一个数组来存储每个点的状态，最开始只有 A 点的状态是确定的，A 点到 A 点的距离初始化为 0，然后初始化 A 点到其余各点的距离，如果 A 点到某一个点没有路径，则初始化为无穷大。从 A 点开始迭代，更新 A 点到到各点的最短距离，如下图所示
这时我们能确定 A 点到 C 点的最短距离是 3，然后就将 C 点的状态设置为确定，再从 C 点开始迭代，继续更新到其余未确定点之间的最小距离，如下图
这时我们确定了，A 点到 B 点的最短距离是 5，然后将 B 点设置为确定，再更新其他未确定的点。直到最终目的地的点被标注为已确定，如下图所示
这样我们就得到了 A 点到 E 点的最短路径 18. 下面我们用代码来实现上面的算法。
代码实现 我们采用邻接矩阵来实现 dijkstra 算法
#include &amp;lt;stdlib.h&amp;gt; #include &amp;lt;stddef.h&amp;gt; #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;string.h&amp;gt; #define INF 10000001 #define N 101 int graph[N][N]; void dijkstra(int *distance, int *flag, int n) { int a, b; for (int i = 0; i &amp;lt; n - 1; i++) { a = -1; b = INF; for (int j = 1; j &amp;lt; n; j++) { // 找出发点到 j 点的最小距离 if (flag[j] == 0 &amp;amp;&amp;amp; distance[j] &amp;lt; b) { a = j; b = distance[j]; } } if (a == -1) { // 没有路到终点 break; } if (a == n - 1) { // 已经找到了到终点的最短路 break; } flag[a] = 1; // 改为固定标号 for (int j = 1; j &amp;lt; n; j++) { if (flag[j] == 0 &amp;amp;&amp;amp; (b + graph[a][j] &amp;lt; distance[j])) { distance[j] = b + graph[a][j]; } } } if (distance[n - 1] &amp;gt;= INF) { printf(&amp;quot;Impossible!</description>
    </item>
    
    <item>
      <title>Hamiltonian Graph | 哈密顿图</title>
      <link>https://root-zr.github.io/en/2022/12/31/hamiltonian-graph-%E5%93%88%E5%AF%86%E9%A1%BF%E5%9B%BE/</link>
      <pubDate>Sat, 31 Dec 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/12/31/hamiltonian-graph-%E5%93%88%E5%AF%86%E9%A1%BF%E5%9B%BE/</guid>
      <description>这篇博客是对上一篇博客欧拉图的补充，主要介绍中国邮递员问题和哈密顿图。
中国邮递员问题 中国邮递员问题是说现在有一个邮递员，他每一天要从邮局出发给自己负责的街道去送信，送完之后再回到邮局，问怎样走路程最短？
这个问题和欧拉图非常相似，特别地，如果这个邮递员负责的街道刚好可以构成一个欧拉图，那么最短的路程就是欧拉回路，因为相当于每条街道刚好走了一次。否则就会存在一条街道被走多次的情况，下面我们就来分析这种情况下的处理办法。
我们已经知道如果一个图存在欧拉回路，每个节点的度数一定是偶数。所以要想把一个图变成欧拉图，就需要把它的奇度数节点都变成偶度数节点，就需要在原图中增加一些边。为了保证路程最小，我们需要对加的边进行一些调整，下面有一些被证明的结论
 最优方案中，图中每条边的重数一定是小于等于2的（一条街道最多走两次）； 图中每个基本回路上平行边的总权值不大于该回路的权值的一半。  哈密顿图 邮递员问题解决的是送货上门的情况，对于蜂巢快递柜这种情况就不是很适用。我们不妨假设邮局和快递柜都是节点，它们之间的路为边，对于这个问题，我们则是希望遍历所有的节点，最后再回到原点，这和之前的遍历所有的边就不一样了。假如存在这样的一个回路，使得我们可以刚好遍历每个节点一次，最终回到原点，这个回路就被称之为哈密顿回路，存在哈密顿回路的图被称为哈密顿图。
这个问题看起来和欧拉图比较类似，只是将边换成了节点，但是目前却没有一个能求解这个问题的充要条件，这看起来是一个令人沮丧的消息，但是我们可以有一些充分条件来判断某个图是不是哈密顿图。
 如果G = &amp;lt;V, E&amp;gt; 是一个有 n 个节点的简单图，对于任意两个不想邻的节点u, v，则一定有deg(u) + deg(v) &amp;gt;= n - 1。  上面的结论可以很有效地帮助我们去判断某个图是不是哈密顿图。</description>
    </item>
    
    <item>
      <title>Euler Graph | 欧拉图</title>
      <link>https://root-zr.github.io/en/2022/12/17/euler-graph-%E6%AC%A7%E6%8B%89%E5%9B%BE/</link>
      <pubDate>Sat, 17 Dec 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/12/17/euler-graph-%E6%AC%A7%E6%8B%89%E5%9B%BE/</guid>
      <description>戈尼斯堡七桥问题 我们先来看一个经典问题。假如有两座小岛，大的小岛和旁边的陆地有四座桥相连，小的岛和陆地有两座桥相连，两个小岛之间有一座桥相连。相当于说有四座陆地，七座桥，问从任何一块陆地出发，每座桥只走一次，最终能否回到原点。类似的问题是一笔画问题（从某一个点出发，不能提起笔，问最终能否回到原点）。
我们可以把上面的问题抽象成右上角所示的图模型，点表示陆地，连线表示桥，这就构成了一个图模型。我们现在来考虑怎么对这个模型进行表达。
图的表示 对于上面的这个图模型来说，我们从数学上可以得到三个集合，点的集合V(G)，边的集合E(G)和边到实数的一个映射函数F(G)（通常表示权重）。在计算机中则是主要通过邻接矩阵和邻接表这两种方式来表示图。
邻接矩阵 邻接矩阵是一个二维的方阵，其中 matrix[i] [j] 用来表达节点 i 和节点 j 是否关联。在图初始化的时候通常以二维数组的方式作为输入，其中第二维表示两个节点和节点之间的关系，比如下面的这个输入就表示节点 1 和节点 2 之间是有边的，并且边的权重为 10。在有些情况下权重是可以忽略的，我们更关心节点间是否连通。
1 2 10 为了符合人类的思考方式，往往节点坐标都是从 1 开始的，这里我们也先假设点的坐标是从 1 开始，然后给出邻接矩阵的实现代码。
#define MAX_SIZE 100 int main() { int n, m, u, v; int matrix[MAX_SIZE][MAX_SIZE] = {0}; scanf(&amp;quot;%d%d&amp;quot;, &amp;amp;n, &amp;amp;m); for (int i = 0; i &amp;lt; m; i++) { scanf(&amp;quot;%d%d&amp;quot;, &amp;amp;u, &amp;amp;v); matrix[u - 1][v - 1] = 1; matrix[v - 1][i - 1] = 1; // 无向图的连接方式 } return 0; } 如果边是有权的，我们在最初赋值的时候会给定一个无穷大的值表示不可访问，如果i == j ，权值为 0。</description>
    </item>
    
    <item>
      <title>Memory Allocation of Linux 0.11 | Linux 0.11 内存区域划分</title>
      <link>https://root-zr.github.io/en/2022/10/06/memory-allocation-of-linux-0.11-linux-0.11-%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E5%88%92%E5%88%86/</link>
      <pubDate>Thu, 06 Oct 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/10/06/memory-allocation-of-linux-0.11-linux-0.11-%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E5%88%92%E5%88%86/</guid>
      <description>内存区域划分 Linux 0.11 内核默认最多支持 16M 物理内存。它的内核模块在物理内存的最前端。然后是高速缓冲区，高速缓冲区是磁盘等块设备临时存放数据的地方，高速缓冲区的最高内存地址可以是 4M，下图中高速缓冲区还要扣除显存和 BIOS ROM 占用的部分。剩余部分才是主内存区，如果系统中还有 RAM 虚拟磁盘，主内存区的前段还要扣除虚拟盘所占的内存空间。如下图所示，
我们来看一下具体在代码中的实现， 下面代码中 ROOT_DEV 表示根设备号， buffer_memory_end 表示高速缓冲区的末端地址， memory_end 表示机器的内存数，main_memory_start 则表示主存的开始地址。
ROOT_DEV = ORIG_ROOT_DEV; // 0x901fc drive_info = DRIVE_INFO; // 0x90080 memory_end = (1&amp;lt;&amp;lt;20) + (EXT_MEM_K&amp;lt;&amp;lt;10); memory_end &amp;amp;= 0xfffff000; if (memory_end &amp;gt; 16*1024*1024) memory_end = 16*1024*1024; if (memory_end &amp;gt; 12*1024*1024) buffer_memory_end = 4*1024*1024; else if (memory_end &amp;gt; 6*1024*1024) buffer_memory_end = 2*1024*1024; else buffer_memory_end = 1*1024*1024; main_memory_start = buffer_memory_end; #ifdef RAMDISK 	main_memory_start += rd_init(main_memory_start, RAMDISK*1024); #endif 	mem_init(main_memory_start,memory_end); 上面的代码首先初始化了根设备号和硬盘参数表，然后设置内存的大小为 1M + 扩展内存 * 1024 字节，memory_end &amp;amp;= 0xfffff000; 则是表示忽略不到 4K 的内存数。</description>
    </item>
    
    <item>
      <title>Run Linux with Bochs | Bochs运行Linux操作系统</title>
      <link>https://root-zr.github.io/en/2022/10/04/run-linux-with-bochs-bochs%E8%BF%90%E8%A1%8Clinux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Tue, 04 Oct 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/10/04/run-linux-with-bochs-bochs%E8%BF%90%E8%A1%8Clinux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</guid>
      <description>操作系统是一个神奇的软件，它管理了各种硬件，所以它本身足够复杂。同样也是这个原因导致我们要对操作系统的代码进行调试变得非常困难。
本文是一篇介绍怎样用 Bochs 来运行和调试 Linux 0.11 的博客。选择 Bochs 而不是 VM Ware 的原因是 Bochs 仿真了 X86 的硬件环境和外设，而VM Ware 则是仿真了一些 I/O 功能，其他是依靠 X86实时硬件执行的。这样虽然 Bochs 在速度上不如 VM Ware，但是因为它具备更加精确的状态和时序，所以更适合开发底层系统软件。 Linux 选择 0.11 的原因则是当前的 Linux 版本太过于庞大，基本不可能完全阅读完它的代码。相比之前 0.11 版本的代码总共也就几万行，而且是一个相对完整的操作系统，所以用它是比较适合的。
Bochs安装和运行Linux 我们之前认为 Bochs 更适合操作系统，幸运的是大家都是这么想的，所以我们已经有完善的软件包可以帮助我们完成这一步了。点击这里 可以下载Linux 0.11 的软件包，解压缩之后可以看到下面的内容。
上图中第一个.exe的文件就是Windows 下 Bochs 的安装文件，.rpm 是 Linux 下的安装文件。本文以 Windows 下为例，双击按照常规安装应用软件的方式安装即可。
上图中 .bxrc 文件是 Bochs 的配置文件，它们的参数各不相同。这里简单介绍一下 bochsrc-hd.bxrc。这个配置文件从启动软盘（A盘）加载内核映像文件 booting-0.11-hd，使用硬盘映像文件 hdc-0.11-new.img 第一个分区中的跟文件系统。
在安装完 Bochs 后直接点击 bochsrc-hd.bxrc 就能进入模拟环境，如下图所示。我们看到当前目录下有 hello 的可执行文件，我们可以直接运行它，会在控制台打印出 hello world！
Linux 代码调试 调试代码要用到的是 Bochs 的 debug 功能，类似于 GDB。首先我们要修改 debug.</description>
    </item>
    
    <item>
      <title> From Maximum Convention Number to Cryptography| 从最大公约数到密码学</title>
      <link>https://root-zr.github.io/en/2022/05/12/from-maximum-convention-number-to-cryptography-%E4%BB%8E%E6%9C%80%E5%A4%A7%E5%85%AC%E7%BA%A6%E6%95%B0%E5%88%B0%E5%AF%86%E7%A0%81%E5%AD%A6/</link>
      <pubDate>Thu, 12 May 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/05/12/from-maximum-convention-number-to-cryptography-%E4%BB%8E%E6%9C%80%E5%A4%A7%E5%85%AC%E7%BA%A6%E6%95%B0%E5%88%B0%E5%AF%86%E7%A0%81%E5%AD%A6/</guid>
      <description>这篇博客主要从我们小学时了解的最大公约数概念出发，一步步去了解数之间的关系，最后讲述它们是怎么被应用在密码学当中的。因为篇幅所限，再加上下文中提到的很多相关定理都需要用到离散数学的知识，所以本文中并不涉及到它们的证明，如果您对这些定理的证明感兴趣，请自行查阅相关的书籍。
最大公约数 我们的故事首先从最大公约数讲起，最大公约数是我们非常熟悉的内容了，如果有两个数a和b，存在一个数m，使得m能同时被a和b整除，并且不存在另外比m大且能同时被a和b整除的数，我们就称m是a和b的最大公约数，可以记为 $$ gcd(a,b) = m $$ 这个概念非常明确，如果真的给定了两个数，要去求它的最大公约数，我们也能很显然地相除一种暴力的解法。那就是让i从1到min(a,b)开始不断去判断是否满足同时被a和b整除，满足条件的最大值就是最大公约数。这种做法的时间复杂度也是很显然的，它是O(min(a/2,b/2))。这种做法在a，b都很大的时候显然不是一个值得提倡的做法，所以人们也想了很多办法去优化它，欧几里得算法就是一个很好的优化方案。
我们不妨假设a &amp;gt; b，则a一定可以表示为下面这种形式 $$ a = p \times b + r $$ 其中p表示a除以b的商，r表示余数。同样的b可以表示为 $$ b = q \times r + r_2 $$ 其中q表示b除以r的商，$r_2$表示余数。如此往复，最终我们将会得到余数$r_i$为0的情况，这时它上面的余数就是a和b的最大公约数。我们可以从一个简单的例子来看这个算法，加入a = 64，b = 42，整个过程可以表述为下面的情况。 $$ 64 = 1 \times 42 + 22
$$
$$ 42 = 1 \times 22 + 20
$$
$$ 22 = 1 \times 20 + 2 $$
$$ 20 = 10 \times 2 + 0 $$</description>
    </item>
    
    <item>
      <title>Knapsack Problem | 背包问题</title>
      <link>https://root-zr.github.io/en/2022/02/24/knapsack-problem-%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/</link>
      <pubDate>Thu, 24 Feb 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/02/24/knapsack-problem-%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/</guid>
      <description>01背包问题 有N 件物品和一个容量为bag 的背包。第i 件物品的重量是w[i]，价值是v[i]。 求解将哪些物品装入背包可使价值总和最大。
暴力算法 我们首先想到的应该是穷举所有的可能，然后把最好的那一个给返回。而在穷举的过程种我们需要考虑的问题仅仅是对于第i个物品，到底要不要把它放入背包。所以可以用递归的方式很自然地解决。
/** * * @param w 物品的重量 * @param v 物品的价值 * @param i 第i个物品 * @param alreadyW 已经放入背包的重量 * @param bag 背包所能承受的最大重量 * @return 最大价值 */ public static int recur(int[] w,int[] v,int i,int alreadyW,int bag){ if(alreadyW &amp;gt; bag || i &amp;gt;= w.length) return 0; //背包超重或者没有物品可以装  int totalVal1 = 0,totalVal2 = 0; totalVal1 = recur(w,v,i+1,alreadyW,bag); //第i个物品不放入背包  if(alreadyW+ w[i] &amp;lt;= bag) totalVal2 = recur(w,v,i+1,alreadyW+ w[i],bag) + v[i]; //第i个物品放入背包  return Math.</description>
    </item>
    
    <item>
      <title>the Map Container of C&#43;&#43; STL | c&#43;&#43; STL中的map容器</title>
      <link>https://root-zr.github.io/en/2021/12/23/the-map-container-of-c-stl-c-stl%E4%B8%AD%E7%9A%84map%E5%AE%B9%E5%99%A8/</link>
      <pubDate>Thu, 23 Dec 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/12/23/the-map-container-of-c-stl-c-stl%E4%B8%AD%E7%9A%84map%E5%AE%B9%E5%99%A8/</guid>
      <description>c++的map容器有4种，它们都保存了键值对类型的元素。map容器的元素是pair&amp;lt;const K,T&amp;gt;类型的对象，以K为键，T为值。pair实际上可以看作一个内部有两个元素的结构体，且这两个元素的类型是可以指定的[1] 。
struct pair { typeName1 first; typeName2 second; }; 同时我们注意到pair元素中的键是const指针来修饰的，这表明我们不能去修改它，因为如果修改的话会扰乱容器中元素的顺序。下面我们来具体了解一下这四种容器的具体实现。
1. map&amp;lt;K,T&amp;gt; 这个容器中的元素是有序的，通过less对象按照键来对所有元素排序。map&amp;lt;K,T&amp;gt;中不允许有重复的键。对于每一个pair&amp;lt;const K,T&amp;gt;节点，map&amp;lt;K,T&amp;gt;中一般是以平衡二叉树的形式来存储的，这样可以保证检索一个随机元素所需的时间是 。
1.1 创建容器 创建一个map容器的方法如下：
map&amp;lt;string, int&amp;gt; people; map&amp;lt;string, int&amp;gt; people{ {&amp;#34;Alice&amp;#34;,20},{&amp;#34;Bob&amp;#34;,25} }; map&amp;lt;string, int&amp;gt; people{ pair&amp;lt;string, int&amp;gt;(&amp;#34;Alice&amp;#34;,20), pair&amp;lt;string, int&amp;gt;(&amp;#34;Bob&amp;#34;,25) }; 可以先创建对象，后续再往里面加元素，也可以在初始化的时候添加一些元素。
1.2 插入元素 具体添加元素的api是insert函数，插入的元素类型可以有以下几种，第一种很容易理解，因为map里存放的就是pair类型的对象，第二种在保证类型正确的情况下也能保证正确插入，第三种方式则是根据map的value_type方式来插入。
people.insert(pair&amp;lt;string, int&amp;gt;(&amp;#34;Tom&amp;#34;, 20)); people.insert({ &amp;#34;John&amp;#34;, 21 }); people.insert(map&amp;lt;string, int&amp;gt;::value_type(&amp;#34;Li Hua&amp;#34;, 22)); 除了上面的三种方式以外还可以用类似于数组的方式来插入元素，下表事key，值对应着value。
people[&amp;#34;Tom&amp;#34;] = 20; people[&amp;#34;John&amp;#34;] = 21; people[&amp;#34;Li Hua&amp;#34;] = 22; 1.3 删除元素 删除元素可以用erase函数来实现，首先传入的参数可以是key的值，代码如下所示：
string name = &amp;#34;John&amp;#34;; if (people.</description>
    </item>
    
    <item>
      <title>Deploy Hyperledger Fabric Environment | Hyperledger Fabric安装与部署</title>
      <link>https://root-zr.github.io/en/2021/10/23/deploy-hyperledger-fabric-environment-hyperledger-fabric%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Sat, 23 Oct 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/10/23/deploy-hyperledger-fabric-environment-hyperledger-fabric%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/</guid>
      <description>本文中用到的宿主环境是Ubuntu18.04。
目前Fabric采用Docker容器作为链码执行环境，因此即使在本地运行，链码服务器上也必须要安装Docker环境。我们这个安装环境主要包括Docker环境的配置以及Docker之上的一些Fabric镜像的配置。
整个项目是采用gradle的框架，然后有一个gradle的服务是用来将智能合约部署到服务器，app的文件夹下放置的是整个应用程序的项目。项目的详细信息可以查看下面的仓库地址：
https://gitlab.com/qubing/blockchain_lab_v2.git 安装公共软件包 在开始之前请确保您的操作系统上安装了以下实用程序
 安装ca-certificates，如果路由器里面没导入证书，在部署路由器的时候,路由器可能会不支持从https安装应用。  sudo apt-get install -y apt-transport-https ca-certificates software-properties-common 安装wget，一个从网页自动下载的工具。  sudo apt-get install -y unzip git curl wget vim tree jq 安装gradle  cd /tmp &amp;amp;&amp;amp; wget https://services.gradle.org/distributions/gradle-6.4-bin.zip 解压缩gradle
unzip gradle-6.4-bin.zip 将grade移动到/usr/local/gradle目录下
sudo mv gradle-6.4 /usr/local/gradle 设置配置文件
sudo cat &amp;gt;&amp;gt; ~/.bashrc &amp;lt;&amp;lt;EOF setup gradle environments # ===================== export PATH=$PATH:/usr/local/gradle/bin # ===================== EOF source ~/.bashrc 从http://gitlab.com 下载qubing老师的项目：  git clone https://gitlab.com/qubing/blockchain_lab_v2.git ~/workspace **注意：**这里如果是采用虚拟机下载，可能网速过慢下载不下来，可以选择在Windows上下载下来，然后复制到虚拟机里。</description>
    </item>
    
    <item>
      <title>Source Code of HashMap | HashMap源码学习</title>
      <link>https://root-zr.github.io/en/2021/10/03/source-code-of-hashmap-hashmap%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Sun, 03 Oct 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/10/03/source-code-of-hashmap-hashmap%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/</guid>
      <description>背景 HashMap近年来是Java面试经常会被问到的知识点，现在也有很多的博客对这个做了介绍，但是我个人感觉这些博客的关注点都倾向于面试问答，看完后好像对HashMap还是似懂非懂。所以我想从源代码出发写这一篇内容，因为能力和所学知识有限，如果文章内容有任何问题欢迎大家批评指正！
笔者的JVM版本是hotspot的1.8.0版本，具体细节如下：
首先从Java API文档来看对HashMap的介绍，
可以看到HashMap位于util包下，所有实现的接口为Serializable, Cloneable和Map&amp;lt;K,V&amp;gt;，
子类包括LinkedHashMap和PrinterStateReasons，如下图所示：
以下是官方对HashMap的解释：
HashMap是基于哈希表的Map接口实现。这个实现提供了所有可选的map操作，并允许空值和空键
Hashtable的Key和Value都不能为空。 
这个类不保证映射的顺序；特别是，它不能保证随着时间的推移，顺序将保持不变。在哈希函数将元素正确地分散在存储桶（buckets）中的前提下，这种实现为基本操作（get和put）提供了常数时间的性能。
对集合视图的迭代需要与HashMap实例的capacity（bucket的数量），加上它的大小（键值映射的数量）成比例的时间。因此，如果迭代性能很重要，那么不要将初始容量设置得太高（或者负载系数太低）。
HashMap的实例有两个影响其性能的参数：初始容量（initial capacity）和负载因子（load factor）。容量是哈希表中存储桶的数量，初始容量只是创建哈希表时的容量。负载因子是在哈希表的容量自动增加之前，允许哈希表获得的完整度的度量。当哈希表中的条目数超过负载因子和当前容量的乘积时，哈希表将被rehashed（即，重建内部数据结构），以便哈希表具有大约两倍的存储桶数。
笔者注：这里确实是大约两倍，因为实际上是（容量*负载系数）&amp;laquo;1, 当负载系数为1时才是真正意义上的两倍。 
一般来讲，**默认负载系数（.75）**在时间和空间成本之间提供了一个很好的折衷。较高的值会减少空间开销，但会增加查找成本（反映在HashMap类的大多数操作中，包括get和put）。在设置初始容量时，应考虑map中的预期条目数（number of entries）及其负载系数，以尽量减少rehash操作的次数。如果初始容量大于最大条目数除以负载系数，则不会发生rehash操作。
如果要在HashMap实例中存储多个映射，那么使用足够大的容量创建它将允许更有效地存储映射，而不是让它根据需要执行rehash以增加表。请注意，使用具有相同hashCode（）的多个键肯定会降低任何哈希表的性能。为了改善影响，当键是Comparable时，此类可以使用键之间的比较顺序来帮助打破联系。
Note that this implementation is not synchronized. 如果多个线程同时访问hash map，并且至少有一个线程在结构上修改了该映射，则必须在外部对其进行同步(结构修改是添加或删除一个或多个映射的任何操作；仅仅更改与实例已包含的键相关联的值并不是结构修改。）这通常是通过在自然封装映射的某个对象上进行同步来实现的。如果不存在这样的对象，则应该使用Collections.synchronizedMap方法“包装”映射。最好在创建时执行此操作，以防止对map的意外非同步访问：
Map m=Collections.synchronizedMap（new HashMap（…））； 这个类的所有“集合视图方法”返回的迭代器都是fail-fast 的：如果在迭代器创建之后的任何时候，以任何方式（除了通过迭代器自己的remove方法）对映射进行结构修改，迭代器将抛出ConcurrentModificationException。因此，在面对并发修改时，迭代器会快速而干净地失败，而不是冒着在将来不确定的时间出现任意的、不确定的行为的风险。
注意，不能保证迭代器的fail-fast 行为，因为一般来说，在存在非同步并发修改的情况下，不可能做出任何硬保证。Fail-fast 迭代器会尽最大努力抛出ConcurrentModificationException。因此，编写一个依赖于此异常来保证其正确性的程序是错误的：迭代器的fail-fast行为应该只用于检测bug。
此类是Java集合框架的成员。
以上内容是官方的API文档对HashMap的解释，因为原文档是全英的描述，如果翻译有错还请帮忙指正。下面从HashMap.java类出发来介绍。
基本结构 HashMap.java类总共有两千多行，涉及十多个方法。
成员变量如下：
private static final long serialVersionUID = 362498820763181265L; static final int DEFAULT_INITIAL_CAPACITY = 1 &amp;lt;&amp;lt; 4; // aka 16，初始容量必须是2的幂 //1 &amp;lt;&amp;lt; 4表示将1左移4位，即1 -&amp;gt; 10000（2） = 16，说明初始容量是16 static final int MAXIMUM_CAPACITY = 1 &amp;lt;&amp;lt; 30; //最大容量 static final float DEFAULT_LOAD_FACTOR = 0.</description>
    </item>
    
    <item>
      <title>the behavior of Linux and shell programming | Linux的行为与SHELL编程</title>
      <link>https://root-zr.github.io/en/2021/09/16/the-behavior-of-linux-and-shell-programming-linux%E7%9A%84%E8%A1%8C%E4%B8%BA%E4%B8%8Eshell%E7%BC%96%E7%A8%8B/</link>
      <pubDate>Thu, 16 Sep 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/09/16/the-behavior-of-linux-and-shell-programming-linux%E7%9A%84%E8%A1%8C%E4%B8%BA%E4%B8%8Eshell%E7%BC%96%E7%A8%8B/</guid>
      <description>以root登录linux系统，并进入/proc目录，键入ls命令，查看/proc下的内容 终端显示的界面如下：
Proc 目录下主要目录和文件的内容有：
Ioports I/O 端口的使用，Kcore 内核核心印象，Kmsg 内核消息，Ksyms 内核符号表，Loadavg 负载均衡，Locks 内核锁，Misc 杂项，Modules 加载模块列表，Mounts加载的文件系统，Partitions 系统识别的分区表，Rtc 实时时钟，Slabinfo Slab 池信息，还有一些其他的信息可参见下表：
   文件名 文件内容     proc/apm 高级电源管理信息   /proc/cmdline 加载kernel时所执行的相关参数。此文件可帮助了解系统是如何启动的   /proc/cpuinfo 本机的CPU相关信息，包含频率、类型与运算功能等   /proc/devices 记录了系统各个主要设备的主要设备代号，与mknod有关   /proc/dma 使用的DMA通道   /proc/filesystems 目前系统已经加载的文件系统   /proc/interrupts 目前系统的IRQ分配状态   /proc/ioports 目前系统的各个设备所配置的IO地址   /proc/kcore 内存的大小   /proc/loadavg top和uptime上面的三个平均数值   /proc/meminfo 使用free列出的内存信息，在这也能查阅   /proc/mounts 系统已经挂载的数据，就是用mount命令调出来的数据   /proc/swaps 系统加载的内存，使用的分区记录   /proc/stat 全面统计状态表   /proc/partitions 使用fdisk -l会出现目前所有的分区，这个文件中也有记录   /proc/version 内核版本   /proc/uptime 系统正常运行时间    查看每个文件的读写权限,如fs文件夹,输入指令</description>
    </item>
    
    <item>
      <title>LinkedList Source Sode | LinkedList源码学习</title>
      <link>https://root-zr.github.io/en/2021/07/26/linkedlist-source-sode-linkedlist%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Mon, 26 Jul 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/07/26/linkedlist-source-sode-linkedlist%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/</guid>
      <description>基本结构 LinkedList是Java对线性表的一种实现，它实现的接口有List, Deque, Cloneable, java.io.Serializable，同时它也继承了util包下的AbstractSequentialList抽象类。
LinkedList是用链表来实现List接口的，它对链表的封装如下：
private static class Node&amp;lt;E&amp;gt; { E item; Node&amp;lt;E&amp;gt; next; Node&amp;lt;E&amp;gt; prev; Node(Node&amp;lt;E&amp;gt; prev, E element, Node&amp;lt;E&amp;gt; next) { this.item = element; this.next = next; this.prev = prev; } } 它的成员变量如下：
private static final long serialVersionUID = 876323262645176354L; //序列化号 transient int size = 0; //链表的大小，transient关键字载序列化对象的时候，这个属性就不会被序列化 transient Node&amp;lt;E&amp;gt; first; //链表的头结点 transient Node&amp;lt;E&amp;gt; last; //链表的尾结点 构造方法如下：
public LinkedList() { //无参构造方法 } public LinkedList(Collection&amp;lt;? extends E&amp;gt; c) { //传一个Collection的对象  this(); addAll(c); } 从前面的有参构造方法可以看出，它要求传入一个实现了Collection接口的类，这个接口为线性表，向量，栈，队列等定义了共同的操作。在传了一个Collection的对象（接口本身是不能创建对象的，这里只是为了说明方便）之后会调用addAll()方法来初始化，这是一个封装好的方法，方法内部会调用它的重载方法，多传入一个index的参数，这个参数值在方法内部默认为size。方法的实现如下：</description>
    </item>
    
    <item>
      <title>red black tree | 红黑树</title>
      <link>https://root-zr.github.io/en/2021/07/24/red-black-tree-%E7%BA%A2%E9%BB%91%E6%A0%91/</link>
      <pubDate>Sat, 24 Jul 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/07/24/red-black-tree-%E7%BA%A2%E9%BB%91%E6%A0%91/</guid>
      <description>问题引入 我们先从二叉查找树开始谈起，在足够理想的情况下，二叉查找树和快速排序非常类似，树的根节点就是快排的第一个切分元素pivot，并且满足左子结点小于root，右子结点的值大于root。他们都是使用了分治法的思想。并且一棵保持平衡的二叉查找树（BST）在平均的情况下查询的时间复杂度能达到 O(log n)。
这是一个可以被我们接受的时间复杂度。不过因为二叉查找树的所有操作所需的时间都和树的高度成正比，假如这个数退化成一个链表，那查询速度将会大打折扣。如果我们始终保持这棵树是平衡的，这个可以实现，但是也要花费很大的成本。如下图，插入1之后大量的结点发生了调整。
为了优化这个问题，人们就考虑在一个树的结点中保存多个值，这样就能减少高度的增加。最直观的想法就是让一个结点可以保存不超过2个值，如下图：
我们保证结点中的值都是从小到大排列的，并且可以看到单个值对应有两个孩子（2-结点），两个值的结点对应3个孩子（3-结点）。所以我们把这种数据结构叫2-3树。
可以看到树上的所有叶子都在一个层次上，因此2-3树总是保持高度平衡的。它的查找效率也能保证在 O(log n)。虽然看似只是进行了一点小小的优化，但一个10个结点的2-3树高度只在19-30之间，这实际上是一个很惊人的数据了。
但是我们怎么插入新的元素呢，假如我们采取和查找一样的方式，直接插到尾部，那将无法保持平衡。所以必须做一些规定：
 假如要插入的元素位置的父结点是一个2-结点，那我们就将这个2-结点变成3-结点，把新元素加进去就行 如果父结点是一个3-结点，我们要把它变成一个4-结点，然后根据不同情况做拆分：  这个4-结点的父结点为2-结点，就将4-结点中最中间的值加进2-结点中，把2-结点变成3-结点，然后剩下的最小的元素和最大的元素拆成两个2-结点接到下面； 这个4-结点的父结点为3-结点，采取和1一样的做法，一直往上做拆分，直到找到一个父结点是2-结点。如果到根节点都不满足根节点是一个2-结点，那根节点就会变成一个临时的4-结点，然后把这个4-结点拆成3个2-结点，使得树的高度增加1.    以上就是所有插入的变换情况，可以看到整个过程中树都是保持平衡的，而且和二叉查找树自上而下生长的方式不同，2-3树是自下而上生长的。
红黑树 基本概念 我们已经对插入进行了设计，下面要做的就是真正实现这种数据结构了。不难想到，我们可以构建2-结点和3-结点的类，然后根据上面的算法不断的变换来实现它。事实上这么做当然没问题，但是却面临两个难点：
 首先是结点之间的数据需要来回变换，效率低，消耗资源； 另外真正实现起来也比较容易出错。  所以科学家就根据这种思路实现了红黑二叉查找树的这种数据结构来高效地进行优化，方便我们进行代码实现，也减少了数据之间的来回变化。
我们知道普通的二叉查找树的高度不好控制，所以我们才允许一个结点出现多个值来降低高度。那我们能不能只是在逻辑上采用这种思想，但是实际上还是采用二叉查找树的结构呢。毕竟这种结构实在是有很多好处。所以有了下面的这种实现，如下图：
如果我们把二叉树的某一个链接放平，可以看到树的高度明显减小了1，而且在本质上这棵树是没有发生变化的。同样的，我们把这两个结点合起来不就正好是一个3-结点吗。
红黑树实际上就是将3-结点拆开了，然后把较大的值作为父结点，较小的值作为子结点，这样就能用一个2-结点的数据结构来实现。只要我们把父结点放平，再把这两个结点合起来，它们就构成了一个3-结点。
为了便于区分我们到底把哪个链接放平了，我们就要给这个链接做个特殊的颜色标记，把它标记为红色，如上图所示。但是我们知道链接是结点这个类里面的一个成员变量，它指向某一个结点，所以我们就直接把它指向的这个结点的颜色标记为红色，其余的颜色为黑色。但是为了便于理解，我们还是约定某一个结点的颜色指的是指向该结点的链接的颜色。结点的数据结构如下：
class Node&amp;lt;Key,Value&amp;gt;{ Key key; Value val; Node&amp;lt;Key,Value&amp;gt; left,right; boolean color; //红色为true,黑色为false  public Node(Key key, Value val,boolean color){ this.key = key; this.val = val; this.color = color; } …… } 现在我们来说明它具有的几个特征：
（1) 空链接的颜色为黑色，这也说明根结点中的颜色标记为黑色，因为指向根节点的链接是空链接；
（2）红链接全是左链接；
（3）没有任何一个结点同时和两条红链接相连，因为如果将2-3树的3-结点画成红色左链接相连的两个2-结点，必然不会存在能够和两条红色链接相连的结点；
（4）任意空链接到根结点的路径上的黑链接数量相同，该树完美黑色平衡。
要使这棵树完美黑色平衡，以上条件必须满足。如果不满足，就必须进行调整，调整的策略就是对树进行旋转和颜色转换。</description>
    </item>
    
    <item>
      <title>KMP Algorithm | KMP算法</title>
      <link>https://root-zr.github.io/en/2021/07/23/kmp-algorithm-kmp%E7%AE%97%E6%B3%95/</link>
      <pubDate>Fri, 23 Jul 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/07/23/kmp-algorithm-kmp%E7%AE%97%E6%B3%95/</guid>
      <description>背景 KMP算法是用来解决字符串的匹配问题的。对于字符串匹配问题，我们首先想到的就是暴力破解法。
用指针i,j来说明，第一个位置下标以0开始。如果匹配则继续比较下一位。否则将j的值清0，i的值也要回到最开始匹配成功的位置重新开始比较，如下图。
public int strStr(String haystack, String needle) { if (needle == &amp;#34;&amp;#34;) { return 0; } for (int i = 0; i &amp;lt; haystack.length() - needle.length() + 1; i++) { for (int j = 0; j &amp;lt; needle.length(); j++) { if (needle.charAt(j) != haystack.charAt(j + i)) { break; } if (j == needle.length() - 1) { return i; } } } return -1; } 暴力算法有一个很严重的问题就是一旦不匹配就要从目标字符串的第一个字符开始从头计算。如果是人为来寻找的话，我们肯定不会这样做，因为主串匹配失败的位置(i=3)前面除了第一个A之外再也没有A了，我们为什么能知道主串前面只有一个A？因为我们已经知道前面三个字符都是匹配的[1] 。换句话说是我们知道匹配失败位置之前的元素都不是A，所以我们可以直接将i指针移动到下图所示的位置：
这样就避免了回退的问题，其实前面的例子中要匹配的字符串（ABCE）中并没有出现相同的字符，所以多少会有一点巧合的意思。现在我们用另外一个例子来说明。假设文档的字符串source = &amp;ldquo;abaabaabca&amp;rdquo;, 目标字符串target = &amp;ldquo;abaabca&amp;rdquo;</description>
    </item>
    
    <item>
      <title>deploy mysql on ubuntu OS | ubuntu配置mysql数据库</title>
      <link>https://root-zr.github.io/en/2021/06/19/deploy-mysql-on-ubuntu-os-ubuntu%E9%85%8D%E7%BD%AEmysql%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
      <pubDate>Sat, 19 Jun 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/06/19/deploy-mysql-on-ubuntu-os-ubuntu%E9%85%8D%E7%BD%AEmysql%E6%95%B0%E6%8D%AE%E5%BA%93/</guid>
      <description>使用的ubuntu版本为18.04，mysql的版本为5.7
下载MySQL 首先使用linux命令下载到本地：
wget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.25-linux-glibc2.12-x86_64.tar.gz 然后解压缩
tar -xvf mysql-5.7.25-linux-glibc2.12-x86_64.tar.gz 注意：为了方便，之后的命令一律采用root账户来配置
移动到/usr/local/并且将mysql-5.7.25-linux-glibc2.12-x86_64重命名为mysql
mv mysql-5.7.25-linux-glibc2.12-x86_64 /usr/local/mysql 创建mysql用户组和用户并修改权限 groupadd mysql useradd -r -g mysql mysql 创建数据目录并赋予权限
mkdir -p /data/mysql #创建目录 chown mysql:mysql -R /data/mysql #赋予权限 配置my.cnf文件，用以下命令打开
vim /etc/my.cnf 文件的内容如下[1] ：
[mysqld] bind-address=0.0.0.0 port=3306 user=mysql basedir=/usr/local/mysql datadir=/data/mysql socket=/tmp/mysql.sock log-error=/data/mysql/mysql.err pid-file=/data/mysql/mysql.pid #character config character_set_server=utf8mb4 symbolic-links=0 explicit_defaults_for_timestamp=true 其中bind-address=0.0.0.0是设置允许远程连接，port=3306表示端口号为3306.
完成上面的步骤之后我们就可以进行数据库的初始化工作了，首先进入mysql的bin目录
cd /usr/local/mysql/bin/ 然后执行bin目录下的mysqld脚本，用来初始化信息，
./mysqld --defaults-file=/etc/my.cnf --basedir=/usr/local/mysql/ --datadir=/data/mysql/ --user=mysql --initialize 这里的user=mysql其实不重要，后续可以设置成root
但是很不幸它报错了，错误信息是./mysqld: error while loading shared libraries: libaio.so.1: cannot open shared object file。其实原因是我们没有下载libaio这个安装包，那我们就下载一个呗，命令如下：</description>
    </item>
    
    <item>
      <title>Error: &#39;DT_ Dir&#39; not declared (first used in this function) | ‘DT_DIR’未声明(在此函数内第一次使用) 解决办法</title>
      <link>https://root-zr.github.io/en/2021/06/17/error-dt_-dir-not-declared-first-used-in-this-function-dt_dir%E6%9C%AA%E5%A3%B0%E6%98%8E%E5%9C%A8%E6%AD%A4%E5%87%BD%E6%95%B0%E5%86%85%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%BD%BF%E7%94%A8-%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</link>
      <pubDate>Thu, 17 Jun 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/06/17/error-dt_-dir-not-declared-first-used-in-this-function-dt_dir%E6%9C%AA%E5%A3%B0%E6%98%8E%E5%9C%A8%E6%AD%A4%E5%87%BD%E6%95%B0%E5%86%85%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%BD%BF%E7%94%A8-%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</guid>
      <description>在编写Linux系统下执行的C语言文件时报错
错误：‘DT_DIR’未声明(在此函数内第一次使用)
解决办法： 需要事先导入对应的依赖
#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;dirent.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;errno.h&amp;gt;然后在编译的时候加上 -D_BSD_SOURCE[1] ，即只需要在我上面的指令基础上变成
gcc difftree.c -lpthread -D_BSD_SOURCE -o difftree.sh --std=c99 然后就能成功编译了
上面指令的-lpthread是因为使用的编译器版本的for循环不支持将int型变量定义在括号内的情况，需要指定编译器的版本才能成功进行编译。这里选择的是最新的编译器版本C99。
参考  ^ https://www.it1352.com/369511.html  </description>
    </item>
    
    <item>
      <title>The Non-recursion Algorithmic of Merging Sort and QuickSort|快速排序和归并排序的非递归实现</title>
      <link>https://root-zr.github.io/en/2021/05/07/the-non-recursion-algorithmic-of-merging-sort-and-quicksort%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E5%92%8C%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E7%9A%84%E9%9D%9E%E9%80%92%E5%BD%92%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Fri, 07 May 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/05/07/the-non-recursion-algorithmic-of-merging-sort-and-quicksort%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E5%92%8C%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E7%9A%84%E9%9D%9E%E9%80%92%E5%BD%92%E5%AE%9E%E7%8E%B0/</guid>
      <description>目前网络上和教材种对这两种排序算法大多是采用递归的方式来实现的，但是非递归的方式较少。另外这两种排序算法也各有特点，像是一对孪生兄弟。首先快排是先排序后分块，归并是先分块后排序，这点在递归方式实现中体现地尤为明显；同时快排是不稳定的排序，归并是稳定的排序；快排不需要额外的内存空间，而归并需要一个和输入数组相同的内存空间。
快速排序的非递归实现 如上所述，快排是要先把一个元素排到对应的位置然后再分块，这个很容易用栈来实现，同时在遇到将递归转为非递归的问题的时候，我们可以首先思考用栈能否实现。具体代码如下：
public static int[] QuickSort(int[] arr, int left, int right) { Stack&amp;lt;Integer&amp;gt; stack = new Stack&amp;lt;&amp;gt;(); if (left &amp;lt; right) { stack.push(left); stack.push(right); while (!stack.isEmpty()) { int height = stack.pop(); int low = stack.pop(); int index = partition(arr, low, height); if (index - 1 &amp;gt; low) { stack.push(low); stack.push(index - 1); } if (index + 1 &amp;lt; height) { stack.push(index + 1); stack.push(height); } } } return arr; } private static int partition(int[] list, int first, int last) { int pivot = list[first]; int low = first + 1; int high = last; while (high &amp;gt; low) { while (low &amp;lt;= high &amp;amp;&amp;amp; list[low] &amp;lt;= pivot) low++; while (low &amp;lt;= high &amp;amp;&amp;amp; list[high] &amp;gt; pivot) high--; if (high &amp;gt; low) { int temp = list[high]; list[high] = list[low]; list[low] = temp; } } while (high &amp;gt; first &amp;amp;&amp;amp; list[high] &amp;gt;= pivot) high--; if (pivot &amp;gt; list[high]) { list[first] = list[high]; list[high] = pivot; return high; } else { return first; } } 归并排序的非递归实现 归并不同于快排，它要求首先把整个数组分成最小的块，每个块是有序的，然后再逐层往上排序。这样就使得没法用栈来实现。具体的代码如下：</description>
    </item>
    
    <item>
      <title>Linux create process and thread instance | Linux创建进程，线程实例</title>
      <link>https://root-zr.github.io/en/2021/04/22/linux-create-process-and-thread-instance-linux%E5%88%9B%E5%BB%BA%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E5%AE%9E%E4%BE%8B/</link>
      <pubDate>Thu, 22 Apr 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/04/22/linux-create-process-and-thread-instance-linux%E5%88%9B%E5%BB%BA%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E5%AE%9E%E4%BE%8B/</guid>
      <description>环境准备  本文采用的操作系统是CentOS7 需要事先安装好gcc和g++环境，分别用来编译c和c++代码  安装命令如下[1] ：
# 安装gcc yum install gcc #安装 g++ yum install gcc-c++ 这里yum为centos的安装命令，Ubuntu的安装命令为apt-get。
进程实例 1.实例描述
首先在linux下编写一个应用程序，命名为an_ch2_1b。这个程序不断地输出如下行：
Those output come from child,[系统时间] 另外写一个应用程序，命名为an_ch2_1a。这个程序创建一个子进程，执行an_ch2_1b。
2.具体步骤
首先创建一个索引目录exer用来存放脚本代码，然后转到exer目录下，使用指令
cat &amp;gt; an_ch2_1b.cpp &amp;lt;&amp;lt; EOF 来创建C++脚本文件，EOF表示在文件中输入EOF退出。
输入an_ch2_1b.cpp的代码如下：
#include &amp;lt;iostream&amp;gt;#include &amp;lt;string&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;time.h&amp;gt;using namespace std; string getTime() // 获取系统时间 { time_t timep; time(&amp;amp;timep); char tmp[64]; strftime(tmp, sizeof (tmp), &amp;#34;%Y-%m-%d%H:%M:%S&amp;#34; ,localtime(&amp;amp;timep)); return tmp; } int main() { while ( true ) { string tmn = getTime(); cout &amp;lt;&amp;lt; &amp;#34;Those output come from child,&amp;#34; &amp;lt;&amp;lt; tmn &amp;lt;&amp;lt; endl; sleep(1); // 为了便于截屏使用sleep() 函数延迟输出  } return 0; } 编写完成之后就需要对源代码进行编译，输入如下指令进行编译</description>
    </item>
    
    <item>
      <title>Xshell remote connect to ubuntu | Xshell远程连接ubuntu</title>
      <link>https://root-zr.github.io/en/2021/03/23/xshell-remote-connect-to-ubuntu-xshell%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5ubuntu/</link>
      <pubDate>Tue, 23 Mar 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/03/23/xshell-remote-connect-to-ubuntu-xshell%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5ubuntu/</guid>
      <description>本文采用的版本是Xshell7和ubuntu18.04，默认是刚安装ubuntu操作系统时的情况。
获取主机IP 首先打开Xshell，新建会话
这里名称可以随便起，然后就需要知道要连接主机的ip，同时连接的协议是SSH，首先解决主机IP的问题，打开ubuntu的终端，输入ifconfig，结果发现出现了
我们按照提示输入指令
sudo apt install net-tools 这里的sudo是用管理员权限，所以可能需要输入密码，然后可能会出现以下情况，显示资源暂时不可用，如果没有这种情况可以忽略解决这个问题的部分，继续进行下面的步骤：
这时需要用管理员权限把上面提示的目录删掉，删除命令就是rm
sudo rm /var/lib/dpkg/lock 这时执行sudo apt install net-tools就能成功安装了，然后执行指令ifconfig就可以看到对应的ip了。
安装SSH服务 然后解决SSH的问题，因为系统里可能没有SSH服务，所以同样需要重新安装，然后启动SSH服务，查看状态是否正常，如果状态正常就可以继续进行远程连接了，具体安装SSH服务可以参考下面的博客：
ubuntu远程连接_ANDY-CSDN博客_ubuntu远程连接blog.csdn.net/qq_34510308/article/details/101433987 看到如下界面表示连接成功
另外在远程连接过程中需要输入用户名和密码，这里对应的就是ubuntu的系统用户名以及密码。</description>
    </item>
    
  </channel>
</rss>
