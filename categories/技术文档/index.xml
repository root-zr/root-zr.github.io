<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>技术文档 on Albert Wang</title>
    <link>https://root-zr.github.io/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3/</link>
    <description>Recent content in 技术文档 on Albert Wang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Oct 2023 13:39:37 +0800</lastBuildDate><atom:link href="https://root-zr.github.io/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Deploy Cluster System with Docker Swarm and Docker Machine | 使用 Docker Swarm 和 Docker Machine 部署集群</title>
      <link>https://root-zr.github.io/en/2023/10/03/deploy-cluster-system-with-docker-swarm-and-docker-machine-%E4%BD%BF%E7%94%A8-docker-swarm-%E5%92%8C-docker-machine-%E9%83%A8%E7%BD%B2%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Tue, 03 Oct 2023 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2023/10/03/deploy-cluster-system-with-docker-swarm-and-docker-machine-%E4%BD%BF%E7%94%A8-docker-swarm-%E5%92%8C-docker-machine-%E9%83%A8%E7%BD%B2%E9%9B%86%E7%BE%A4/</guid>
      <description>这篇博客主要介绍怎么用一台电脑和 Docker 来搭建出一个可以随意扩容服务的集群。因为我的宿主机是 win10 系统，所以我先装了一台 ubuntu18.04 版本的虚拟机。
准备工作 在开始我们下面的操作之前需要先准备一下环境，
 首先我们需要用到的工具是 Docker Machine，Docker Machine 是一个用于简化 Docker 主机（Docker Host）创建、管理和配置的命令行工具。它的主要目标是让用户能够在本地开发环境中或云中轻松创建和管理多个 Docker 主机，而无需深入了解底层虚拟化技术或云提供商的特定配置。你需要确保事先已经安装了这个软件，如果没有的话可以运行下面的命令安装，  base=https://github.com/docker/machine/releases/download/v0.16.2 &amp;amp;&amp;amp; curl -L $base/docker-machine-$(uname -s)-$(uname -m) &amp;gt;/tmp/docker-machine &amp;amp;&amp;amp; sudo install /tmp/docker-machine /usr/local/bin/docker-machine   另外需要安装 VirtualBox，官网是 https://www.virtualbox.org/ 。这里我们选择的是 linux ubuntu 18.04。
  最后需要确保开启了嵌套虚拟化，如果没有开启的话执行创建节点会报下面的错误
  virtualBox 开启是在设置的系统设置里，勾选启动PAE/NX和启用嵌套 VT-x/AMD-V.
启用嵌套 VT-x/AMD-V 如果没有办法勾选的话可以在 CMD 里使用下面的命令开启。先 cd 到 virtualBox 的安装目录，我的是 D:\sys\virtualBox\virtualBox。然后 VBoxManage.exe list vms 查看有哪些虚拟机，最后用 VBoxManage.exe modifyvm &amp;ldquo;name&amp;rdquo; &amp;ndash;nested-hw-virt on 打开指定虚拟机的选项。</description>
    </item>
    
    <item>
      <title>Inno DB | InnoDB</title>
      <link>https://root-zr.github.io/en/2023/09/29/inno-db-innodb/</link>
      <pubDate>Fri, 29 Sep 2023 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2023/09/29/inno-db-innodb/</guid>
      <description>InnoDB存储 InnoDB 存储引擎是 MySQL 中最常用的存储引擎之一，其存储结构是一个复杂的组合，充分利用了磁盘、内存和日志来提供高性能、事务支持和数据一致性。它的存储结构包括以下几个重要的组成部分：
表空间（Tablespaces）： InnoDB 存储引擎的数据存储是基于表空间的，每个表都有自己的表空间，包括系统表空间和用户表空间。系统表空间包含了数据字典等系统信息，而用户表空间包含了用户创建的表和索引数据。表空间实际上由一个或多个数据文件组成，这些数据文件是磁盘上的物理文件，用于存储表的数据和索引。InnoDB 存储引擎的数据文件通常以 .ibd 扩展名结尾。
表空间由三个段的内容组成Leaf node segment，Non-Leaf node segment 和 Rollback segment
 Leaf node segment：主要存的是表里的记录 Non-Leaf node segment：主要存主键索引和从索引 Rollback segment：存储事务回滚的数据  我们主要介绍段的概念。正如上面列举的那样，段里面主要存储了数据，那它就需要支持我们去动态扩增，而扩增的单位就是 Extend，默认的大小是 1M。一个 Extend 里有 64 个 Page，所以 1 个 Page 的大小为 16K（一次从磁盘读进来的数据就是一页 16 K）。Page 里则是存储着真实的记录，但是由于记录大小本身不固定，所以 1 个 Page 里有多少条记录也是不确定的。
页是由下图所示的这几部分组成的，数据主要存储在 User Records 里， User Records 里存储的数据可能是按照主键由小到大排列，也可能是无序的插入，这个和具体的操作相关。如果发生了删除和重新插入这些操作，内部的存储就会更加无序。
我们可以通过 Page Directory 快速找到具体某一行的记录，Page Directory 有序排列了主键，可以通过二分法快速查找。
B+ 树索引结构 InnoDB 存储引擎使用 B+ 树索引结构来管理数据，包括聚集索引和辅助索引。聚集索引是表的主键索引，决定了数据在磁盘上的物理存储顺序，而辅助索引用于加速查询。
B+树中叶子节点是以 Page 为单位进行存储的。并且两个页之间的主键是有序的。既然是树结构存储，那就必然需要处理增删改查这些场景，尤其是对于插入数据时需要对页进行拆分的情况，如果插入操作导致数据页的分裂，InnoDB 还需要更新父节点的索引，以反映分裂操作的结果。 为了确保数据的持久性，InnoDB 会将插入操作写入重做日志（redo log）。这是为了在发生崩溃或故障时能够恢复插入操作。写入重做日志是一个必要的步骤，以保证事务的原子性和持久性。为了使分页的代价降到最低，一般来说主键都是自增的，不允许随意去定义。</description>
    </item>
    
    <item>
      <title>Messaging Service 2 | 消息服务2 </title>
      <link>https://root-zr.github.io/en/2023/09/16/messaging-service-2-%E6%B6%88%E6%81%AF%E6%9C%8D%E5%8A%A12/</link>
      <pubDate>Sat, 16 Sep 2023 13:39:39 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2023/09/16/messaging-service-2-%E6%B6%88%E6%81%AF%E6%9C%8D%E5%8A%A12/</guid>
      <description>从上一篇博客中我们知道两台服务器之间的通信可以采用消息队列的方式。使用这种方式的好处在于生产者和消费者之间完全实现了异步通信，生产者只需要生产消息到消息队列，然后任意一个消费者都可能在往后的某个时间消费这个消息，但是消息只可以被一个消费者消费。这也就间接出现了一个生产者只会对应一个消费者的场景，实现了一种点对点的通信模式。
图1 上面的模式是一种很不错的设计方案，假如有一天负载突然增大，我们也可以通过不断增加生产者服务器和消费者服务器来应对。但是这种模式也存在一个问题，加入我们现在有一笔订单，生产者把订单加入消息队列，这时我们希望和订单相对应的多个消费者都做出相应的处理，只用点对点的模式就会比较麻烦，它也会限制我们后续业务的扩展。这时可以采用发布订阅的模式来处理，生产者依然发送消息到消息队列，消息队列会把消息发送给所有订阅了这个消息队列的消费者。我们在上一篇博客的例子中就采用 epoll 的方式来实现了订阅消息队列的这种方式。当所有的消费者都消费完了这条消息，这条消息才会从消息队列中被删除。
图2 下面我们来介绍一个消息服务很成熟的例子rocketmq ，在 Apache RocketMQ 里有一个主题（Topic）的定义，官方文档中称它是消息传输和存储的顶层容器，用于标识同一类业务逻辑的消息。
图3 同样还有一个消费者分组（ConsumerGroup）的概念也需要被提及，消费者组被定义为多个消费行为一致的消费者。下面我们举个例子来说明一下这个分组意义，假设下图中的两个组分别代表商品和顾客，当消息队列中有一笔订单过来的时候商品和顾客这两个组中的服务器应当各自只有一台会消费这个数据，但是这个商品和顾客这两个组都是订阅了这个消息的。也就是说通过这种机制来很好地结合了点对点通信和发布订阅模式的通信。
图4 下面就是 RocketMQ 的架构实例，我们至少需要两台消息服务器，一台是 NameServer，它用来管理所有的 BrokerServer，当生产者起来的时候它会首先通过 NameServer 获取到 BrokerServer 的信息，然后就会和 BrokerServer 之间发送信息，同样地，消费者也会采用这样的方式。从下图中我们很容易发现不管是 NameServer 还是 BrokerServer，他们都是可以被用作集群的，原因也很简单，假如 NameServer 宕机了，那整个消息服务就瘫痪了，所以会采用多个服务器备份的方式来搭建集群。
图5 值得一提的是在上面的图中没有画出来消费者订阅 BrokerServer 的信息不光可以从主服务器上订阅，也可以从被服务器上订阅，这样可以加大消费者处理的性能，当然满足这种订阅机制的前提是主备服务器之间的数据是保证具备了强一致性的。
我们从图 3 和图 4 中是可以看到一个 BrokerServer 里是有多个消息队列的，这样可以增加消息被并行消费的能力，因为假如只有一个队列的话就会存在互斥的信息，有些消费者组就需要等待。如果包拯一个消费者组有一个属于自己的消息队列，每个消费者都从自己订阅的队列里拿消息，这样会持续增加消息队列的性能。
下面我们讨论一下消息服务器的事务处理，在我之前的博客中总结过分布式事务常见的两阶段提交法，如果您有兴趣的话可以点击这里 查看。两阶段提交法作为分布式事务而言一个很大的弊端就是它会降低性能，而消息服务器基本都是为了应对高并发的场景而存在的，所以 RocketMQ 对消息服务的事务也进行了一些处理来满足这样的场景。
下图是对 RocketMQ 事务消息的一个总结，首先生产者将消息发送至Apache RocketMQ服务端，然后 brokerServer 收到消息之后会先把消息进行持久化在返回成功给生产者，对应下图中的1，2两步。这个时候生产者开始执行本地事务逻辑，生产者根据本地事务执行结果向服务端提交二次确认结果（Commit或是Rollback），服务端收到确认结果后处理逻辑如下：
 Commit：将消息标记为可投递，并投递给消费者。 Rollback：回滚事务。  第五步如果服务端未收到发送者提交的二次确认结果，或服务端收到的二次确认结果为Unknown未知状态，经过固定时间后，服务端将对消息生产者即生产者集群中任一生产者实例发起消息回查。生产者收到消息回查后，需要检查对应消息的本地事务执行的最终结果。
最后我们总结一下消息服务器的作用：
 可以用来进行模块间解耦：模块之间只需要发消息，不需要去调用对方的API； 可以具备队列所具有的FIFO的特点； 可以做到“削峰填谷”，起到一个缓冲的作用。  参考资料：
 中国大学慕课JavaEE之Spring框架：https://www.icourse163.org/learn/XMU-1462056168 rocketmq官网：https://rocketmq.apache.org/  </description>
    </item>
    
    <item>
      <title>Messaging Service 1 | 消息服务1 </title>
      <link>https://root-zr.github.io/en/2023/09/16/messaging-service-1-%E6%B6%88%E6%81%AF%E6%9C%8D%E5%8A%A11/</link>
      <pubDate>Sat, 16 Sep 2023 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2023/09/16/messaging-service-1-%E6%B6%88%E6%81%AF%E6%9C%8D%E5%8A%A11/</guid>
      <description>一般来说两台服务器之间的通信都可以简单抽象成两个进程之间的通信，而进程之间的通信有管道，消息队列，共享内存等各种的通信方式。我们的故事先从两个进程之间的通信说起。进程之间的通信有管道，消息队列，共享内存等各种通信方式，其中消息队列是一种非常方便于我们理解的方式。比如下面这个例子，我们可以首先创建一个消息队列，然后载创建两个线程 send_tid, receive_tid，它们两个线程分别承担了生产者和消费者的角色，前者发送消息到消息队列，后者从消息队列中获取消息。
在开始之前我们先定义下面的一些表示，包括消息的封装（分为消息类型和内容），消息队列的标识（用来唯一标识这个消息队列）和epoll描述符（我们生产者需要不断从消息队列中epoll出数据）。
struct message { long msg_type; char msg_text[256]; }; int msg_id; // 消息队列标识符 int epoll_fd; // epoll描述符 然后我们实现第一个线程用来发送消息到消息队列，在下面这个例子中每隔 2S 写一条消息到消息队列中，因为是 while (1)，所以这个线程永远不会退出。
void *send_thread(void *arg) { struct message msg; int msg_count = 1; while (1) { msg.msg_type = 1; // 构造消息内容 snprintf(msg.msg_text, sizeof(msg.msg_text), &amp;quot;Message %d from send_thread&amp;quot;, msg_count); // 发送消息到消息队列 if (msgsnd(msg_id, &amp;amp;msg, sizeof(msg), 0) == -1) { perror(&amp;quot;msgsnd&amp;quot;); exit(1); } printf(&amp;quot;Sent: %s\n&amp;quot;, msg.msg_text); msg_count++; sleep(2); } return NULL; } 接收消息的线程相比较于发送消息的线程稍微复杂了一点，因为这里用到了 epoll 的系统调用。当消息队列中有事件被监听到之后会通知消费者去处理消息。在这个例子中增加 epoll 的原因是在没有事件发生时，线程会自动进入睡眠状态，不会浪费资源。一旦有事件发生，线程将被唤醒来处理这些事件。这使得 epoll 成为处理大量并发连接的有效工具，因为它能够高效地管理和处理事件而不会占用大量线程资源。</description>
    </item>
    
    <item>
      <title>The Shortest Path of Graphs | 图的最短路问题3</title>
      <link>https://root-zr.github.io/en/2023/05/02/the-shortest-path-of-graphs-%E5%9B%BE%E7%9A%84%E6%9C%80%E7%9F%AD%E8%B7%AF%E9%97%AE%E9%A2%983/</link>
      <pubDate>Tue, 02 May 2023 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2023/05/02/the-shortest-path-of-graphs-%E5%9B%BE%E7%9A%84%E6%9C%80%E7%9F%AD%E8%B7%AF%E9%97%AE%E9%A2%983/</guid>
      <description>对于下面这个 3 * 3 的矩阵来说，如果我们想要从从左上角走到右下角，每次只能走一步，问怎么走距离最短。
假如现在有一个问题，对于下面这个 3 * 3 的矩阵来说，如果我们想要从从左上角走到右下角，每次只能走一步，问怎么走距离最短？
这个题目我们一般就直接采用 BFS 计算出结果，这样做无疑是最方便的。但是我们同样可以先构建图，然后再使用 dijkstra 算法来计算最小路径。上面的矩阵可以被表示为下面这样的一张图，
但是我们用邻接表表示这张图就稍微有点困难了，因为一般来说我们表示图的某一个节点一般是用一个数字 i （ 0 &amp;lt;= i &amp;lt; n） 来表示的，但是这回的顶点确是用（i， j）这一个点对来表示的。所以我们邻接表的数据结构用数组 + 链表就不太方便了，这时可以用 Map 来表示。
在 Java 语言的实现中一般是要用 HashMap，这时就要考虑可能出现哈希碰撞的情况，比较有效的一个办法是重写 hashCode 函数，如下图中的 Pair 对象。关于为什么要重写 hashCode 函数可以参考我这篇博客 。
class Pair { int x; int y; int distance; public Pair(int x, int y, int distance) { this.x = x; this.y = y; this.distance = distance; } public int hashCode() { return (x &amp;lt;&amp;lt; 16) | y; } public boolean equals(Object a) { Pair obj = (Pair)a; if (obj == null) { return false; } return this.</description>
    </item>
    
    <item>
      <title>DFS and BFS with Graph | 无向图深度优先与广度优先</title>
      <link>https://root-zr.github.io/en/2023/05/01/dfs-and-bfs-with-graph-%E6%97%A0%E5%90%91%E5%9B%BE%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E4%B8%8E%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88/</link>
      <pubDate>Mon, 01 May 2023 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2023/05/01/dfs-and-bfs-with-graph-%E6%97%A0%E5%90%91%E5%9B%BE%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E4%B8%8E%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88/</guid>
      <description>背景 我们来看这样一道经典的题目，一个矩阵中有 0 和 1 两种元素，现在要从左上角开始遍历，每次可以选择八个方向，并且只能访问值为 0 的节点，问它最短需要走多少步才能到达，查看原题可以点击这里 。
这就是一个非常典型的遍历无向图的例子了，下面我们分别介绍 DFS 和 BFS 需要注意些什么。
DFS 我们先假设在上图中机器人先选择向下走了一步，然后它就到了（1，0）这个点，在这个点上它可以选择向任意四个方向前进，但是又不能走出去，所以它可选的方向就只有三个，分别是向下，向右和向上。假如它选择了向上，那它就又回到了（0，0）这个点，当它回到原点之后它有可以选择来到（1，0），这样重复之后程序就永远不可能会退出了。
针对这种情况我们来思考一下解决办法，之所以出现这种情况，是因为它走了重复的路。而它一旦走了重复的路，那这条路必然就不可能是最短的路，所以我们要禁止这种情况的发生。代码里通常有两种做法来避免这种情况的发生，一种是很直观的禁止它走“回头路”，代码实现如下
class Solution { int ans; int[][] paths = new int[][]{{1, 0}, {-1, 0}, {0, 1}, {0, -1}, {1, 1}, {1, -1}, {-1, 1}, {-1, -1}}; boolean[][] isVisited; public boolean valid(int[][] grid, int x, int y) { if (x &amp;lt; 0 || x &amp;gt;= grid.length || y &amp;lt; 0 || y &amp;gt;= grid[0].length) { return false; } if (isVisited[x][y] || grid[x][y] == 1) { return false; } return true; } public void backtrack(int[][] grid, int x, int y, int cnt) { if (!</description>
    </item>
    
    <item>
      <title>The Shortest Path of Graphs | 图的最短路问题2</title>
      <link>https://root-zr.github.io/en/2023/04/22/the-shortest-path-of-graphs-%E5%9B%BE%E7%9A%84%E6%9C%80%E7%9F%AD%E8%B7%AF%E9%97%AE%E9%A2%982/</link>
      <pubDate>Sat, 22 Apr 2023 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2023/04/22/the-shortest-path-of-graphs-%E5%9B%BE%E7%9A%84%E6%9C%80%E7%9F%AD%E8%B7%AF%E9%97%AE%E9%A2%982/</guid>
      <description>在几个月前我总结了图最短路问题常用的几个算法以及实现 。但是随后我就发现了一个很大的问题，之前算法的实现都是采用的邻接矩阵，这种实现方式最大的问题就是太占用内存空间。假如一个稀疏图有 n 个顶点，m 条边（其中 m &amp;laquo; n)，在这种情况下用邻接矩阵来表示图需要的内存空间是$O(n^2)$，在一些算法题中 n 的数量往往会达到 $10^5$，而给定的内存范围是 $10^9$，这就导致临界矩阵往往不能用来做这些图的题目。如果采用邻接表来表示一个图只需要 $O(n + m)$ 的内存空间，所以下面我们用邻接表来实现Dijkstra 算法。
首先我们来构造图，代码如下。其中 n 表示有 n 个节点，并且节点的值为 0 ~ n - 1，edges 表示边的集合，edge[0]和edge[1]表示从 edge[0] 到 edge[1] 有边，edge[2] 表示这条边的权重。
 public int init(int n, int[][] edges) { ArrayList&amp;lt;Node&amp;gt;[] graph = new ArrayList[n]; for (int i = 0; i &amp;lt; n; i++) { graph[i] = new ArrayList&amp;lt;&amp;gt;(); } for (int[] edge : edges) { graph[edge[0]].add(new Node(edge[1], edge[2])); graph[edge[1]].</description>
    </item>
    
    <item>
      <title>Override equals and hashCode method in HashMap | Java使用HashMap需要重写equals和hashCode方法的场景</title>
      <link>https://root-zr.github.io/en/2023/04/21/override-equals-and-hashcode-method-in-hashmap-java%E4%BD%BF%E7%94%A8hashmap%E9%9C%80%E8%A6%81%E9%87%8D%E5%86%99equals%E5%92%8Chashcode%E6%96%B9%E6%B3%95%E7%9A%84%E5%9C%BA%E6%99%AF/</link>
      <pubDate>Fri, 21 Apr 2023 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2023/04/21/override-equals-and-hashcode-method-in-hashmap-java%E4%BD%BF%E7%94%A8hashmap%E9%9C%80%E8%A6%81%E9%87%8D%E5%86%99equals%E5%92%8Chashcode%E6%96%B9%E6%B3%95%E7%9A%84%E5%9C%BA%E6%99%AF/</guid>
      <description>当我们使用对象类型作为 HashMap 的 key的时候，我们往往希望两个对象里的某一个或者某几个成员变量相等，则这两个对象是相等的，而不是说采用 Java 默认的地址空间一致并且值也相等才表示两个对象相等。
假设我们有一个对象 Node表示一个点，它有两个成员变量 a 和 b
class Node { int a; // 表示从a到b int b; public Node(int a, int b) { this.a = a; this.b = b; } } 现在我们创建一个 HashMap，并且在 map 里存入点（1，1）然后我们获取点（1，1）对应的权重。
public class Test { public static void main(String[] args) { HashMap&amp;lt;Node, Integer&amp;gt; map = new HashMap&amp;lt;&amp;gt;(); Node node = new Node(1, 1); map.put(node, 2); System.out.println(map.get(new Node(1, 1))); } } 我们运行代码可以发现 map 返回的值是 null 而不是 2，这是因为我们在获取的时候又用 new 关键字创建了一个对象，然后在堆区开辟了一块新的内存空间，这导致这个“新的对象”之前并没有存在hash表里。</description>
    </item>
    
    <item>
      <title>Distributed transaction | 分布式事务</title>
      <link>https://root-zr.github.io/en/2023/03/05/distributed-transaction-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</link>
      <pubDate>Sun, 05 Mar 2023 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2023/03/05/distributed-transaction-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</guid>
      <description>背景 在数据库概念中事务代表着一系列的操作，这些操作需要版满足ACID特性，分别是下面这些操作的首字母
  Atomic：这些操作要么全部被commit，要么都不做；
  Consistent： 一个事务在执行之前和执行之后，数据库都必须处于一致性状态
  Isolatesd: 两个事务之间的操作是隔离的，当事务在执行的时候彼此看不到各自的修改，只能看到事务执行结束之后的结果；
  Durability：事务处理的结果必须被持久化，长期存在
  如果数据库只保存在一台服务器上，设计满足ACID的属性在一般的数据库书籍中都会讲到。但是在大型系统中，数据库的一张表往往保存在多个服务器上，比如银行的存款信息可能一半在A服务器，一半在B服务器，在这种情况之下设计满足ACID的分布式事务就会麻烦很多。
比如我们现在有两个事务 T1 和 T2， 其中 T1 是表示从 x 到 y 的一个转账操作，x 和 y 的值最初都是 10，并且分别保存在服务器 A 和 B 上，T2 表示一次查询操作，它们分别可以用下面这种方式执行
T1 ： BEGIN_X add(x, 1) add(y, -1) END_X T2: BEGIN_X t1 = get(x) t2 = get(y) print t1, t2 END_X 下面我们用两阶段提交的方式来设计分布式事务。
两阶段提交 在两阶段提交方式中有一个专门的服务器用来做事务协调器，A，B 这些服务器叫参与者（paticipants）。首先协调器会发prepare消息给参与者，判断它们能否完成后续的put操作，协调器会回复 YES/NO，分别表示下图中的①和②。当协调器发现两个服务都回复了 YES，协调器会发 commit 消息，参与者 commit 之后会回复 ACK 确认消息，只要有一个回复NO，就会发abort消息，回滚这个事务，如下图的③和④。通过这两个阶段就保证了分布式事务的一致性。</description>
    </item>
    
    <item>
      <title>Segment Tree | 线段树</title>
      <link>https://root-zr.github.io/en/2023/03/03/segment-tree-%E7%BA%BF%E6%AE%B5%E6%A0%91/</link>
      <pubDate>Fri, 03 Mar 2023 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2023/03/03/segment-tree-%E7%BA%BF%E6%AE%B5%E6%A0%91/</guid>
      <description>背景 这篇博客主要介绍线段树的相关知识。假如我们需要对区间进行操作，比如需要多次查询某一个区间的和，或者多次查询某一个区间的最大值，或者多次在某些区间上加一个值。很明显，我们操作一次的时间复杂度是O(n)，操作 m 次的时间复杂度是 O(mn)。
对于$O(n^2)$ 这样的时间复杂度来说，我们的数据量一般不能超过$10^5$，但是如果我们有一种手段把它的时间复杂度变成nlogn级别，那效率就会提升很多。
线段树 线段树就是一种很好的解决方案。它的图形化表达如下图所示；
假如我们想要查询某一个区间的和，首先我们知道总的区间是[1, 10]，然后我们把他进行折半，分成[1, 5] 和 [6, 10] 两个区间。然后对这两个子区间再折半，不断地递归下去，知道这个区间已经只有一个元素，也就是对应着叶子节点。
这时对于叶子节点我们很容易知道它的和就是这个元素本身，因为它只有一个元素。对于任意一个非叶子节点来说，它的区间和就是先对它的子结点求和，再把每一个子结点的和相加。
代码实现 不难看出，线段树其实是一棵完全二叉树，所以我们直接用一个一维数组就可以保存树节点信息，类似于堆的存储方式。同样的，对于下标从 0 开始的节点，第 i 棵树必然满足下面的性质
 左子节点下标 2 * i + 1; 右子节点下标 2 * i + 2  我们先来定义每一个节点的的类，用 left, right, sum 分别表示左右子结点和当前区间的和。
class Node { int left; int right; int sum; public Node (int left, int right, int sum) { this.left = left; this.right = right; this.sum = sum; } } 下面就是线段树的实现，它的成员变量就是一个一维数组，用来保存这棵树的节点信息。为了保证空间足够，这里我们按照 num * 4 的规格来创建数组空间。</description>
    </item>
    
    <item>
      <title>Trie Tree | 字典树</title>
      <link>https://root-zr.github.io/en/2023/02/19/trie-tree-%E5%AD%97%E5%85%B8%E6%A0%91/</link>
      <pubDate>Sun, 19 Feb 2023 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2023/02/19/trie-tree-%E5%AD%97%E5%85%B8%E6%A0%91/</guid>
      <description>背景 假如我们现在有一个单词组成的数组[&amp;ldquo;apple&amp;rdquo;, &amp;ldquo;banana&amp;rdquo;, &amp;ldquo;orange&amp;rdquo;, &amp;hellip;]，我们希望准确地知道某一个单词是否在这个数组里，有什么高效的统计方式呢？
字典树 字典树的设计就是用来解决上面的问题，下图就是一个字典树的示意图，它具有以下的特点：
 它的每条边代表了一个特定的字符； 从根节点到每个节点的路径就是某个字符串的前缀； 一个父结点的子结点数目最多有 26 个，因为只有 26 个单词.  对于下面这张图来说，我们希望知道 &amp;ldquo;cat&amp;rdquo; 在不在字典里，首先我们从根节点出发，先找第一个单词 &amp;lsquo;c&amp;rsquo; 在不在根节点的子结点里；如果在，就找第二个单词 &amp;lsquo;a&amp;rsquo; 在不在 &amp;lsquo;c&amp;rsquo; 的子结点里，这样不断地查找下去。
我们不难发现，对于这棵树来说，它的深度取决于当前字典里最长单词的字母个数，而单词的长度一般不会超过 50，所以这棵树的查找是非常高效的。
字典树除了能很好地判断一个单词是否在这个字典里，它同样可以应用于自动补全和拼写检查。
代码实现 要实现这棵树也非常简单，首先我们需要把这棵树的节点构造出来，这里用一个长度为 26 的数组用来表示某一个字母是否有对应的子结点，还有一个 int 的变量用来表示在这颗树里有多少个单词以当前这个节点结尾。
class Node { Node[] next; int end; public Node() { next = new Node[26]; } } 然后我们需要实现 Trie 的代码，我们只需要通过迭代的方式去插入和查询即可。
public class Trie { Node root; public Trie() { root = new Node(); } public void insert(String word) { char[] arr = word.</description>
    </item>
    
    <item>
      <title>Append Entries of Raft | Raft算法添加条目</title>
      <link>https://root-zr.github.io/en/2023/02/11/append-entries-of-raft-raft%E7%AE%97%E6%B3%95%E6%B7%BB%E5%8A%A0%E6%9D%A1%E7%9B%AE/</link>
      <pubDate>Sat, 11 Feb 2023 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2023/02/11/append-entries-of-raft-raft%E7%AE%97%E6%B3%95%E6%B7%BB%E5%8A%A0%E6%9D%A1%E7%9B%AE/</guid>
      <description>这篇博客主要记录 raft 算法添加日志条目的过程，这里用到的一些代码和思路主要来源于 MIT 6.824 课程 , 课程中提供的材料raft 论文 和 Github 上一些开源的代码实现。
raft 算法主要是以一种 lib 库的方式嵌入在应用程序中来保证分布式系统的一致性。在课程的实验中将 raft 将项目的结构划分成了下图所示这种方式。
我们假设现在是一个由三台服务器组成的分布式集群（为了保证投票时“大多数”的条件永远成立，这里集群的数目必须是奇数），每台服务器的上层都维护了一个 &amp;lt; key, value &amp;gt; 的数据库，下层是 raft 算法的实现，它们通过 raft.go 里的 Start 函数做为接口进行交互。
在我们彻底弄懂上面那张图表达的意思之前让我们先来了解一下 raft 本身维护了哪些状态，下面的结构体里展示了 raft 自身的全部状态，针对这篇博客的内容，我们大概只需要了解我中文注释的这一部分就可以。这里有些状态是针对 leader 的，有些是 follower 的，有些则是它们共有的属性。分布式系统往往有成百上千台机器，而每台服务器上跑的代码都是一样的。所以当我们在编写代码的时候，必须对什么样的角色可以执行这段代码时刻保持清醒的认知。否则有些流程可能只有 leader 才会执行，如果我们没有事先检验调用者的身份，就会导致 follower 也会执行这部分代码，在一个分布式系统中这种操作导致出错的可能性是非常高的。
type Raft struct { mu sync.Mutex // 用来保证状态一致性的锁 peers []*labrpc.ClientEnd // 保存了集群中每一台服务器的信息，在我们的例子中是3台 persister *Persister // Object to hold this peer&#39;s persisted state me int // “我”这台服务器在 peers 中的位置 dead int32 // set by Kill() state RaftState // Follower, Candidate, Leader 3种状态 appendEntryCh chan *Entry heartBeat time.</description>
    </item>
    
    <item>
      <title>The Shortest Path of Graphs | 图的最短路问题</title>
      <link>https://root-zr.github.io/en/2023/01/07/the-shortest-path-of-graphs-%E5%9B%BE%E7%9A%84%E6%9C%80%E7%9F%AD%E8%B7%AF%E9%97%AE%E9%A2%98/</link>
      <pubDate>Sat, 07 Jan 2023 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2023/01/07/the-shortest-path-of-graphs-%E5%9B%BE%E7%9A%84%E6%9C%80%E7%9F%AD%E8%B7%AF%E9%97%AE%E9%A2%98/</guid>
      <description>问题背景 假设我们有下面这张图，图中边的权重表示两点之间的距离。我们希望找到一条最短的路径从这张图的 A 点出发，最终走到 E 点，该怎样考虑这个问题呢？
这个问题很具有现实的意义，假设两点表示两个城市的距离，我们往往希望能够走最短距离的那条路到达目的地。而且这个问题也有一个隐含的条件，那就路的距离不可能为负数，所以我们可以考虑使用 Dijkstra 算法来进行求解。
Dijkstra 算法 Dijkstra 算法考虑对每一个点进行标号，每个点对应着两种状态（固定标号和临时标号，表示已经确定最短路径和尚未确定），一开始只有出发点的状态是已经确定最短路径的，然后会在迭代的时候去更新标号点，同时也会对每个点的最短路径进行更新。
图表模拟 下面我们先用图表的方式来进行模拟 Dijkstra 的求解过程。首先我们用一个数组来存储每个点的状态，最开始只有 A 点的状态是确定的，A 点到 A 点的距离初始化为 0，然后初始化 A 点到其余各点的距离，如果 A 点到某一个点没有路径，则初始化为无穷大。从 A 点开始迭代，更新 A 点到到各点的最短距离，如下图所示
这时我们能确定 A 点到 C 点的最短距离是 3，然后就将 C 点的状态设置为确定，再从 C 点开始迭代，继续更新到其余未确定点之间的最小距离，如下图
这时我们确定了，A 点到 B 点的最短距离是 5，然后将 B 点设置为确定，再更新其他未确定的点。直到最终目的地的点被标注为已确定，如下图所示
这样我们就得到了 A 点到 E 点的最短路径 18. 下面我们用代码来实现上面的算法。
代码实现 我们采用邻接矩阵来实现 dijkstra 算法
#include &amp;lt;stdlib.h&amp;gt; #include &amp;lt;stddef.h&amp;gt; #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;string.h&amp;gt; #define INF 10000001 #define N 101 int graph[N][N]; void dijkstra(int *distance, int *flag, int n) { int a, b; for (int i = 0; i &amp;lt; n - 1; i++) { a = -1; b = INF; for (int j = 1; j &amp;lt; n; j++) { // 找出发点到 j 点的最小距离 if (flag[j] == 0 &amp;amp;&amp;amp; distance[j] &amp;lt; b) { a = j; b = distance[j]; } } if (a == -1) { // 没有路到终点 break; } if (a == n - 1) { // 已经找到了到终点的最短路 break; } flag[a] = 1; // 改为固定标号 for (int j = 1; j &amp;lt; n; j++) { if (flag[j] == 0 &amp;amp;&amp;amp; (b + graph[a][j] &amp;lt; distance[j])) { distance[j] = b + graph[a][j]; } } } if (distance[n - 1] &amp;gt;= INF) { printf(&amp;quot;Impossible!</description>
    </item>
    
    <item>
      <title>Hamiltonian Graph | 哈密顿图</title>
      <link>https://root-zr.github.io/en/2022/12/31/hamiltonian-graph-%E5%93%88%E5%AF%86%E9%A1%BF%E5%9B%BE/</link>
      <pubDate>Sat, 31 Dec 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/12/31/hamiltonian-graph-%E5%93%88%E5%AF%86%E9%A1%BF%E5%9B%BE/</guid>
      <description>这篇博客是对上一篇博客欧拉图的补充，主要介绍中国邮递员问题和哈密顿图。
中国邮递员问题 中国邮递员问题是说现在有一个邮递员，他每一天要从邮局出发给自己负责的街道去送信，送完之后再回到邮局，问怎样走路程最短？
这个问题和欧拉图非常相似，特别地，如果这个邮递员负责的街道刚好可以构成一个欧拉图，那么最短的路程就是欧拉回路，因为相当于每条街道刚好走了一次。否则就会存在一条街道被走多次的情况，下面我们就来分析这种情况下的处理办法。
我们已经知道如果一个图存在欧拉回路，每个节点的度数一定是偶数。所以要想把一个图变成欧拉图，就需要把它的奇度数节点都变成偶度数节点，就需要在原图中增加一些边。为了保证路程最小，我们需要对加的边进行一些调整，下面有一些被证明的结论
 最优方案中，图中每条边的重数一定是小于等于2的（一条街道最多走两次）； 图中每个基本回路上平行边的总权值不大于该回路的权值的一半。  哈密顿图 邮递员问题解决的是送货上门的情况，对于蜂巢快递柜这种情况就不是很适用。我们不妨假设邮局和快递柜都是节点，它们之间的路为边，对于这个问题，我们则是希望遍历所有的节点，最后再回到原点，这和之前的遍历所有的边就不一样了。假如存在这样的一个回路，使得我们可以刚好遍历每个节点一次，最终回到原点，这个回路就被称之为哈密顿回路，存在哈密顿回路的图被称为哈密顿图。
这个问题看起来和欧拉图比较类似，只是将边换成了节点，但是目前却没有一个能求解这个问题的充要条件，这看起来是一个令人沮丧的消息，但是我们可以有一些充分条件来判断某个图是不是哈密顿图。
 如果G = &amp;lt;V, E&amp;gt; 是一个有 n 个节点的简单图，对于任意两个不想邻的节点u, v，则一定有deg(u) + deg(v) &amp;gt;= n - 1。  上面的结论可以很有效地帮助我们去判断某个图是不是哈密顿图。</description>
    </item>
    
    <item>
      <title>Euler Graph | 欧拉图</title>
      <link>https://root-zr.github.io/en/2022/12/17/euler-graph-%E6%AC%A7%E6%8B%89%E5%9B%BE/</link>
      <pubDate>Sat, 17 Dec 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/12/17/euler-graph-%E6%AC%A7%E6%8B%89%E5%9B%BE/</guid>
      <description>戈尼斯堡七桥问题 我们先来看一个经典问题。假如有两座小岛，大的小岛和旁边的陆地有四座桥相连，小的岛和陆地有两座桥相连，两个小岛之间有一座桥相连。相当于说有四座陆地，七座桥，问从任何一块陆地出发，每座桥只走一次，最终能否回到原点。类似的问题是一笔画问题（从某一个点出发，不能提起笔，问最终能否回到原点）。
我们可以把上面的问题抽象成右上角所示的图模型，点表示陆地，连线表示桥，这就构成了一个图模型。我们现在来考虑怎么对这个模型进行表达。
图的表示 对于上面的这个图模型来说，我们从数学上可以得到三个集合，点的集合V(G)，边的集合E(G)和边到实数的一个映射函数F(G)（通常表示权重）。在计算机中则是主要通过邻接矩阵和邻接表这两种方式来表示图。
邻接矩阵 邻接矩阵是一个二维的方阵，其中 matrix[i] [j] 用来表达节点 i 和节点 j 是否关联。在图初始化的时候通常以二维数组的方式作为输入，其中第二维表示两个节点和节点之间的关系，比如下面的这个输入就表示节点 1 和节点 2 之间是有边的，并且边的权重为 10。在有些情况下权重是可以忽略的，我们更关心节点间是否连通。
1 2 10 为了符合人类的思考方式，往往节点坐标都是从 1 开始的，这里我们也先假设点的坐标是从 1 开始，然后给出邻接矩阵的实现代码。
#define MAX_SIZE 100 int main() { int n, m, u, v; int matrix[MAX_SIZE][MAX_SIZE] = {0}; scanf(&amp;quot;%d%d&amp;quot;, &amp;amp;n, &amp;amp;m); for (int i = 0; i &amp;lt; m; i++) { scanf(&amp;quot;%d%d&amp;quot;, &amp;amp;u, &amp;amp;v); matrix[u - 1][v - 1] = 1; matrix[v - 1][i - 1] = 1; // 无向图的连接方式 } return 0; } 如果边是有权的，我们在最初赋值的时候会给定一个无穷大的值表示不可访问，如果i == j ，权值为 0。</description>
    </item>
    
    <item>
      <title>Memory Allocation of Linux 0.11 | Linux 0.11 内存区域划分</title>
      <link>https://root-zr.github.io/en/2022/10/06/memory-allocation-of-linux-0.11-linux-0.11-%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E5%88%92%E5%88%86/</link>
      <pubDate>Thu, 06 Oct 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/10/06/memory-allocation-of-linux-0.11-linux-0.11-%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E5%88%92%E5%88%86/</guid>
      <description>内存区域划分 Linux 0.11 内核默认最多支持 16M 物理内存。它的内核模块在物理内存的最前端。然后是高速缓冲区，高速缓冲区是磁盘等块设备临时存放数据的地方，高速缓冲区的最高内存地址可以是 4M，下图中高速缓冲区还要扣除显存和 BIOS ROM 占用的部分。剩余部分才是主内存区，如果系统中还有 RAM 虚拟磁盘，主内存区的前段还要扣除虚拟盘所占的内存空间。如下图所示，
我们来看一下具体在代码中的实现， 下面代码中 ROOT_DEV 表示根设备号， buffer_memory_end 表示高速缓冲区的末端地址， memory_end 表示机器的内存数，main_memory_start 则表示主存的开始地址。
ROOT_DEV = ORIG_ROOT_DEV; // 0x901fc drive_info = DRIVE_INFO; // 0x90080 memory_end = (1&amp;lt;&amp;lt;20) + (EXT_MEM_K&amp;lt;&amp;lt;10); memory_end &amp;amp;= 0xfffff000; if (memory_end &amp;gt; 16*1024*1024) memory_end = 16*1024*1024; if (memory_end &amp;gt; 12*1024*1024) buffer_memory_end = 4*1024*1024; else if (memory_end &amp;gt; 6*1024*1024) buffer_memory_end = 2*1024*1024; else buffer_memory_end = 1*1024*1024; main_memory_start = buffer_memory_end; #ifdef RAMDISK 	main_memory_start += rd_init(main_memory_start, RAMDISK*1024); #endif 	mem_init(main_memory_start,memory_end); 上面的代码首先初始化了根设备号和硬盘参数表，然后设置内存的大小为 1M + 扩展内存 * 1024 字节，memory_end &amp;amp;= 0xfffff000; 则是表示忽略不到 4K 的内存数。</description>
    </item>
    
    <item>
      <title>Run Linux with Bochs | Bochs运行Linux操作系统</title>
      <link>https://root-zr.github.io/en/2022/10/04/run-linux-with-bochs-bochs%E8%BF%90%E8%A1%8Clinux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Tue, 04 Oct 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/10/04/run-linux-with-bochs-bochs%E8%BF%90%E8%A1%8Clinux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</guid>
      <description>操作系统是一个神奇的软件，它管理了各种硬件，所以它本身足够复杂。同样也是这个原因导致我们要对操作系统的代码进行调试变得非常困难。
本文是一篇介绍怎样用 Bochs 来运行和调试 Linux 0.11 的博客。选择 Bochs 而不是 VM Ware 的原因是 Bochs 仿真了 X86 的硬件环境和外设，而VM Ware 则是仿真了一些 I/O 功能，其他是依靠 X86实时硬件执行的。这样虽然 Bochs 在速度上不如 VM Ware，但是因为它具备更加精确的状态和时序，所以更适合开发底层系统软件。 Linux 选择 0.11 的原因则是当前的 Linux 版本太过于庞大，基本不可能完全阅读完它的代码。相比之前 0.11 版本的代码总共也就几万行，而且是一个相对完整的操作系统，所以用它是比较适合的。
Bochs安装和运行Linux 我们之前认为 Bochs 更适合操作系统，幸运的是大家都是这么想的，所以我们已经有完善的软件包可以帮助我们完成这一步了。点击这里 可以下载Linux 0.11 的软件包，解压缩之后可以看到下面的内容。
上图中第一个.exe的文件就是Windows 下 Bochs 的安装文件，.rpm 是 Linux 下的安装文件。本文以 Windows 下为例，双击按照常规安装应用软件的方式安装即可。
上图中 .bxrc 文件是 Bochs 的配置文件，它们的参数各不相同。这里简单介绍一下 bochsrc-hd.bxrc。这个配置文件从启动软盘（A盘）加载内核映像文件 booting-0.11-hd，使用硬盘映像文件 hdc-0.11-new.img 第一个分区中的跟文件系统。
在安装完 Bochs 后直接点击 bochsrc-hd.bxrc 就能进入模拟环境，如下图所示。我们看到当前目录下有 hello 的可执行文件，我们可以直接运行它，会在控制台打印出 hello world！
Linux 代码调试 调试代码要用到的是 Bochs 的 debug 功能，类似于 GDB。首先我们要修改 debug.</description>
    </item>
    
    <item>
      <title>Knapsack Problem | 背包问题</title>
      <link>https://root-zr.github.io/en/2022/02/24/knapsack-problem-%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/</link>
      <pubDate>Thu, 24 Feb 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/02/24/knapsack-problem-%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/</guid>
      <description>01背包问题 有N 件物品和一个容量为bag 的背包。第i 件物品的重量是w[i]，价值是v[i]。 求解将哪些物品装入背包可使价值总和最大。
暴力算法 我们首先想到的应该是穷举所有的可能，然后把最好的那一个给返回。而在穷举的过程种我们需要考虑的问题仅仅是对于第i个物品，到底要不要把它放入背包。所以可以用递归的方式很自然地解决。
/** * * @param w 物品的重量 * @param v 物品的价值 * @param i 第i个物品 * @param alreadyW 已经放入背包的重量 * @param bag 背包所能承受的最大重量 * @return 最大价值 */ public static int recur(int[] w,int[] v,int i,int alreadyW,int bag){ if(alreadyW &amp;gt; bag || i &amp;gt;= w.length) return 0; //背包超重或者没有物品可以装  int totalVal1 = 0,totalVal2 = 0; totalVal1 = recur(w,v,i+1,alreadyW,bag); //第i个物品不放入背包  if(alreadyW+ w[i] &amp;lt;= bag) totalVal2 = recur(w,v,i+1,alreadyW+ w[i],bag) + v[i]; //第i个物品放入背包  return Math.</description>
    </item>
    
    <item>
      <title>the Map Container of C&#43;&#43; STL | c&#43;&#43; STL中的map容器</title>
      <link>https://root-zr.github.io/en/2021/12/23/the-map-container-of-c-stl-c-stl%E4%B8%AD%E7%9A%84map%E5%AE%B9%E5%99%A8/</link>
      <pubDate>Thu, 23 Dec 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/12/23/the-map-container-of-c-stl-c-stl%E4%B8%AD%E7%9A%84map%E5%AE%B9%E5%99%A8/</guid>
      <description>c++的map容器有4种，它们都保存了键值对类型的元素。map容器的元素是pair&amp;lt;const K,T&amp;gt;类型的对象，以K为键，T为值。pair实际上可以看作一个内部有两个元素的结构体，且这两个元素的类型是可以指定的[1] 。
struct pair { typeName1 first; typeName2 second; }; 同时我们注意到pair元素中的键是const指针来修饰的，这表明我们不能去修改它，因为如果修改的话会扰乱容器中元素的顺序。下面我们来具体了解一下这四种容器的具体实现。
1. map&amp;lt;K,T&amp;gt; 这个容器中的元素是有序的，通过less对象按照键来对所有元素排序。map&amp;lt;K,T&amp;gt;中不允许有重复的键。对于每一个pair&amp;lt;const K,T&amp;gt;节点，map&amp;lt;K,T&amp;gt;中一般是以平衡二叉树的形式来存储的，这样可以保证检索一个随机元素所需的时间是 。
1.1 创建容器 创建一个map容器的方法如下：
map&amp;lt;string, int&amp;gt; people; map&amp;lt;string, int&amp;gt; people{ {&amp;#34;Alice&amp;#34;,20},{&amp;#34;Bob&amp;#34;,25} }; map&amp;lt;string, int&amp;gt; people{ pair&amp;lt;string, int&amp;gt;(&amp;#34;Alice&amp;#34;,20), pair&amp;lt;string, int&amp;gt;(&amp;#34;Bob&amp;#34;,25) }; 可以先创建对象，后续再往里面加元素，也可以在初始化的时候添加一些元素。
1.2 插入元素 具体添加元素的api是insert函数，插入的元素类型可以有以下几种，第一种很容易理解，因为map里存放的就是pair类型的对象，第二种在保证类型正确的情况下也能保证正确插入，第三种方式则是根据map的value_type方式来插入。
people.insert(pair&amp;lt;string, int&amp;gt;(&amp;#34;Tom&amp;#34;, 20)); people.insert({ &amp;#34;John&amp;#34;, 21 }); people.insert(map&amp;lt;string, int&amp;gt;::value_type(&amp;#34;Li Hua&amp;#34;, 22)); 除了上面的三种方式以外还可以用类似于数组的方式来插入元素，下表事key，值对应着value。
people[&amp;#34;Tom&amp;#34;] = 20; people[&amp;#34;John&amp;#34;] = 21; people[&amp;#34;Li Hua&amp;#34;] = 22; 1.3 删除元素 删除元素可以用erase函数来实现，首先传入的参数可以是key的值，代码如下所示：
string name = &amp;#34;John&amp;#34;; if (people.</description>
    </item>
    
    <item>
      <title>Deploy Hyperledger Fabric Environment | Hyperledger Fabric安装与部署</title>
      <link>https://root-zr.github.io/en/2021/10/23/deploy-hyperledger-fabric-environment-hyperledger-fabric%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Sat, 23 Oct 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/10/23/deploy-hyperledger-fabric-environment-hyperledger-fabric%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2/</guid>
      <description>本文中用到的宿主环境是Ubuntu18.04。
目前Fabric采用Docker容器作为链码执行环境，因此即使在本地运行，链码服务器上也必须要安装Docker环境。我们这个安装环境主要包括Docker环境的配置以及Docker之上的一些Fabric镜像的配置。
整个项目是采用gradle的框架，然后有一个gradle的服务是用来将智能合约部署到服务器，app的文件夹下放置的是整个应用程序的项目。项目的详细信息可以查看下面的仓库地址：
https://gitlab.com/qubing/blockchain_lab_v2.git 安装公共软件包 在开始之前请确保您的操作系统上安装了以下实用程序
 安装ca-certificates，如果路由器里面没导入证书，在部署路由器的时候,路由器可能会不支持从https安装应用。  sudo apt-get install -y apt-transport-https ca-certificates software-properties-common 安装wget，一个从网页自动下载的工具。  sudo apt-get install -y unzip git curl wget vim tree jq 安装gradle  cd /tmp &amp;amp;&amp;amp; wget https://services.gradle.org/distributions/gradle-6.4-bin.zip 解压缩gradle
unzip gradle-6.4-bin.zip 将grade移动到/usr/local/gradle目录下
sudo mv gradle-6.4 /usr/local/gradle 设置配置文件
sudo cat &amp;gt;&amp;gt; ~/.bashrc &amp;lt;&amp;lt;EOF setup gradle environments # ===================== export PATH=$PATH:/usr/local/gradle/bin # ===================== EOF source ~/.bashrc 从http://gitlab.com 下载qubing老师的项目：  git clone https://gitlab.com/qubing/blockchain_lab_v2.git ~/workspace **注意：**这里如果是采用虚拟机下载，可能网速过慢下载不下来，可以选择在Windows上下载下来，然后复制到虚拟机里。</description>
    </item>
    
    <item>
      <title>Source Code of HashMap | HashMap源码学习</title>
      <link>https://root-zr.github.io/en/2021/10/03/source-code-of-hashmap-hashmap%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Sun, 03 Oct 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/10/03/source-code-of-hashmap-hashmap%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/</guid>
      <description>背景 HashMap近年来是Java面试经常会被问到的知识点，现在也有很多的博客对这个做了介绍，但是我个人感觉这些博客的关注点都倾向于面试问答，看完后好像对HashMap还是似懂非懂。所以我想从源代码出发写这一篇内容，因为能力和所学知识有限，如果文章内容有任何问题欢迎大家批评指正！
笔者的JVM版本是hotspot的1.8.0版本，具体细节如下：
首先从Java API文档来看对HashMap的介绍，
可以看到HashMap位于util包下，所有实现的接口为Serializable, Cloneable和Map&amp;lt;K,V&amp;gt;，
子类包括LinkedHashMap和PrinterStateReasons，如下图所示：
以下是官方对HashMap的解释：
HashMap是基于哈希表的Map接口实现。这个实现提供了所有可选的map操作，并允许空值和空键
Hashtable的Key和Value都不能为空。 
这个类不保证映射的顺序；特别是，它不能保证随着时间的推移，顺序将保持不变。在哈希函数将元素正确地分散在存储桶（buckets）中的前提下，这种实现为基本操作（get和put）提供了常数时间的性能。
对集合视图的迭代需要与HashMap实例的capacity（bucket的数量），加上它的大小（键值映射的数量）成比例的时间。因此，如果迭代性能很重要，那么不要将初始容量设置得太高（或者负载系数太低）。
HashMap的实例有两个影响其性能的参数：初始容量（initial capacity）和负载因子（load factor）。容量是哈希表中存储桶的数量，初始容量只是创建哈希表时的容量。负载因子是在哈希表的容量自动增加之前，允许哈希表获得的完整度的度量。当哈希表中的条目数超过负载因子和当前容量的乘积时，哈希表将被rehashed（即，重建内部数据结构），以便哈希表具有大约两倍的存储桶数。
笔者注：这里确实是大约两倍，因为实际上是（容量*负载系数）&amp;laquo;1, 当负载系数为1时才是真正意义上的两倍。 
一般来讲，**默认负载系数（.75）**在时间和空间成本之间提供了一个很好的折衷。较高的值会减少空间开销，但会增加查找成本（反映在HashMap类的大多数操作中，包括get和put）。在设置初始容量时，应考虑map中的预期条目数（number of entries）及其负载系数，以尽量减少rehash操作的次数。如果初始容量大于最大条目数除以负载系数，则不会发生rehash操作。
如果要在HashMap实例中存储多个映射，那么使用足够大的容量创建它将允许更有效地存储映射，而不是让它根据需要执行rehash以增加表。请注意，使用具有相同hashCode（）的多个键肯定会降低任何哈希表的性能。为了改善影响，当键是Comparable时，此类可以使用键之间的比较顺序来帮助打破联系。
Note that this implementation is not synchronized. 如果多个线程同时访问hash map，并且至少有一个线程在结构上修改了该映射，则必须在外部对其进行同步(结构修改是添加或删除一个或多个映射的任何操作；仅仅更改与实例已包含的键相关联的值并不是结构修改。）这通常是通过在自然封装映射的某个对象上进行同步来实现的。如果不存在这样的对象，则应该使用Collections.synchronizedMap方法“包装”映射。最好在创建时执行此操作，以防止对map的意外非同步访问：
Map m=Collections.synchronizedMap（new HashMap（…））； 这个类的所有“集合视图方法”返回的迭代器都是fail-fast 的：如果在迭代器创建之后的任何时候，以任何方式（除了通过迭代器自己的remove方法）对映射进行结构修改，迭代器将抛出ConcurrentModificationException。因此，在面对并发修改时，迭代器会快速而干净地失败，而不是冒着在将来不确定的时间出现任意的、不确定的行为的风险。
注意，不能保证迭代器的fail-fast 行为，因为一般来说，在存在非同步并发修改的情况下，不可能做出任何硬保证。Fail-fast 迭代器会尽最大努力抛出ConcurrentModificationException。因此，编写一个依赖于此异常来保证其正确性的程序是错误的：迭代器的fail-fast行为应该只用于检测bug。
此类是Java集合框架的成员。
以上内容是官方的API文档对HashMap的解释，因为原文档是全英的描述，如果翻译有错还请帮忙指正。下面从HashMap.java类出发来介绍。
基本结构 HashMap.java类总共有两千多行，涉及十多个方法。
成员变量如下：
private static final long serialVersionUID = 362498820763181265L; static final int DEFAULT_INITIAL_CAPACITY = 1 &amp;lt;&amp;lt; 4; // aka 16，初始容量必须是2的幂 //1 &amp;lt;&amp;lt; 4表示将1左移4位，即1 -&amp;gt; 10000（2） = 16，说明初始容量是16 static final int MAXIMUM_CAPACITY = 1 &amp;lt;&amp;lt; 30; //最大容量 static final float DEFAULT_LOAD_FACTOR = 0.</description>
    </item>
    
    <item>
      <title>the behavior of Linux and shell programming | Linux的行为与SHELL编程</title>
      <link>https://root-zr.github.io/en/2021/09/16/the-behavior-of-linux-and-shell-programming-linux%E7%9A%84%E8%A1%8C%E4%B8%BA%E4%B8%8Eshell%E7%BC%96%E7%A8%8B/</link>
      <pubDate>Thu, 16 Sep 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/09/16/the-behavior-of-linux-and-shell-programming-linux%E7%9A%84%E8%A1%8C%E4%B8%BA%E4%B8%8Eshell%E7%BC%96%E7%A8%8B/</guid>
      <description>以root登录linux系统，并进入/proc目录，键入ls命令，查看/proc下的内容 终端显示的界面如下：
Proc 目录下主要目录和文件的内容有：
Ioports I/O 端口的使用，Kcore 内核核心印象，Kmsg 内核消息，Ksyms 内核符号表，Loadavg 负载均衡，Locks 内核锁，Misc 杂项，Modules 加载模块列表，Mounts加载的文件系统，Partitions 系统识别的分区表，Rtc 实时时钟，Slabinfo Slab 池信息，还有一些其他的信息可参见下表：
   文件名 文件内容     proc/apm 高级电源管理信息   /proc/cmdline 加载kernel时所执行的相关参数。此文件可帮助了解系统是如何启动的   /proc/cpuinfo 本机的CPU相关信息，包含频率、类型与运算功能等   /proc/devices 记录了系统各个主要设备的主要设备代号，与mknod有关   /proc/dma 使用的DMA通道   /proc/filesystems 目前系统已经加载的文件系统   /proc/interrupts 目前系统的IRQ分配状态   /proc/ioports 目前系统的各个设备所配置的IO地址   /proc/kcore 内存的大小   /proc/loadavg top和uptime上面的三个平均数值   /proc/meminfo 使用free列出的内存信息，在这也能查阅   /proc/mounts 系统已经挂载的数据，就是用mount命令调出来的数据   /proc/swaps 系统加载的内存，使用的分区记录   /proc/stat 全面统计状态表   /proc/partitions 使用fdisk -l会出现目前所有的分区，这个文件中也有记录   /proc/version 内核版本   /proc/uptime 系统正常运行时间    查看每个文件的读写权限,如fs文件夹,输入指令</description>
    </item>
    
    <item>
      <title>LinkedList Source Sode | LinkedList源码学习</title>
      <link>https://root-zr.github.io/en/2021/07/26/linkedlist-source-sode-linkedlist%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Mon, 26 Jul 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/07/26/linkedlist-source-sode-linkedlist%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/</guid>
      <description>基本结构 LinkedList是Java对线性表的一种实现，它实现的接口有List, Deque, Cloneable, java.io.Serializable，同时它也继承了util包下的AbstractSequentialList抽象类。
LinkedList是用链表来实现List接口的，它对链表的封装如下：
private static class Node&amp;lt;E&amp;gt; { E item; Node&amp;lt;E&amp;gt; next; Node&amp;lt;E&amp;gt; prev; Node(Node&amp;lt;E&amp;gt; prev, E element, Node&amp;lt;E&amp;gt; next) { this.item = element; this.next = next; this.prev = prev; } } 它的成员变量如下：
private static final long serialVersionUID = 876323262645176354L; //序列化号 transient int size = 0; //链表的大小，transient关键字载序列化对象的时候，这个属性就不会被序列化 transient Node&amp;lt;E&amp;gt; first; //链表的头结点 transient Node&amp;lt;E&amp;gt; last; //链表的尾结点 构造方法如下：
public LinkedList() { //无参构造方法 } public LinkedList(Collection&amp;lt;? extends E&amp;gt; c) { //传一个Collection的对象  this(); addAll(c); } 从前面的有参构造方法可以看出，它要求传入一个实现了Collection接口的类，这个接口为线性表，向量，栈，队列等定义了共同的操作。在传了一个Collection的对象（接口本身是不能创建对象的，这里只是为了说明方便）之后会调用addAll()方法来初始化，这是一个封装好的方法，方法内部会调用它的重载方法，多传入一个index的参数，这个参数值在方法内部默认为size。方法的实现如下：</description>
    </item>
    
    <item>
      <title>red black tree | 红黑树</title>
      <link>https://root-zr.github.io/en/2021/07/24/red-black-tree-%E7%BA%A2%E9%BB%91%E6%A0%91/</link>
      <pubDate>Sat, 24 Jul 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/07/24/red-black-tree-%E7%BA%A2%E9%BB%91%E6%A0%91/</guid>
      <description>问题引入 我们先从二叉查找树开始谈起，在足够理想的情况下，二叉查找树和快速排序非常类似，树的根节点就是快排的第一个切分元素pivot，并且满足左子结点小于root，右子结点的值大于root。他们都是使用了分治法的思想。并且一棵保持平衡的二叉查找树（BST）在平均的情况下查询的时间复杂度能达到 O(log n)。
这是一个可以被我们接受的时间复杂度。不过因为二叉查找树的所有操作所需的时间都和树的高度成正比，假如这个数退化成一个链表，那查询速度将会大打折扣。如果我们始终保持这棵树是平衡的，这个可以实现，但是也要花费很大的成本。如下图，插入1之后大量的结点发生了调整。
为了优化这个问题，人们就考虑在一个树的结点中保存多个值，这样就能减少高度的增加。最直观的想法就是让一个结点可以保存不超过2个值，如下图：
我们保证结点中的值都是从小到大排列的，并且可以看到单个值对应有两个孩子（2-结点），两个值的结点对应3个孩子（3-结点）。所以我们把这种数据结构叫2-3树。
可以看到树上的所有叶子都在一个层次上，因此2-3树总是保持高度平衡的。它的查找效率也能保证在 O(log n)。虽然看似只是进行了一点小小的优化，但一个10个结点的2-3树高度只在19-30之间，这实际上是一个很惊人的数据了。
但是我们怎么插入新的元素呢，假如我们采取和查找一样的方式，直接插到尾部，那将无法保持平衡。所以必须做一些规定：
 假如要插入的元素位置的父结点是一个2-结点，那我们就将这个2-结点变成3-结点，把新元素加进去就行 如果父结点是一个3-结点，我们要把它变成一个4-结点，然后根据不同情况做拆分：  这个4-结点的父结点为2-结点，就将4-结点中最中间的值加进2-结点中，把2-结点变成3-结点，然后剩下的最小的元素和最大的元素拆成两个2-结点接到下面； 这个4-结点的父结点为3-结点，采取和1一样的做法，一直往上做拆分，直到找到一个父结点是2-结点。如果到根节点都不满足根节点是一个2-结点，那根节点就会变成一个临时的4-结点，然后把这个4-结点拆成3个2-结点，使得树的高度增加1.    以上就是所有插入的变换情况，可以看到整个过程中树都是保持平衡的，而且和二叉查找树自上而下生长的方式不同，2-3树是自下而上生长的。
红黑树 基本概念 我们已经对插入进行了设计，下面要做的就是真正实现这种数据结构了。不难想到，我们可以构建2-结点和3-结点的类，然后根据上面的算法不断的变换来实现它。事实上这么做当然没问题，但是却面临两个难点：
 首先是结点之间的数据需要来回变换，效率低，消耗资源； 另外真正实现起来也比较容易出错。  所以科学家就根据这种思路实现了红黑二叉查找树的这种数据结构来高效地进行优化，方便我们进行代码实现，也减少了数据之间的来回变化。
我们知道普通的二叉查找树的高度不好控制，所以我们才允许一个结点出现多个值来降低高度。那我们能不能只是在逻辑上采用这种思想，但是实际上还是采用二叉查找树的结构呢。毕竟这种结构实在是有很多好处。所以有了下面的这种实现，如下图：
如果我们把二叉树的某一个链接放平，可以看到树的高度明显减小了1，而且在本质上这棵树是没有发生变化的。同样的，我们把这两个结点合起来不就正好是一个3-结点吗。
红黑树实际上就是将3-结点拆开了，然后把较大的值作为父结点，较小的值作为子结点，这样就能用一个2-结点的数据结构来实现。只要我们把父结点放平，再把这两个结点合起来，它们就构成了一个3-结点。
为了便于区分我们到底把哪个链接放平了，我们就要给这个链接做个特殊的颜色标记，把它标记为红色，如上图所示。但是我们知道链接是结点这个类里面的一个成员变量，它指向某一个结点，所以我们就直接把它指向的这个结点的颜色标记为红色，其余的颜色为黑色。但是为了便于理解，我们还是约定某一个结点的颜色指的是指向该结点的链接的颜色。结点的数据结构如下：
class Node&amp;lt;Key,Value&amp;gt;{ Key key; Value val; Node&amp;lt;Key,Value&amp;gt; left,right; boolean color; //红色为true,黑色为false  public Node(Key key, Value val,boolean color){ this.key = key; this.val = val; this.color = color; } …… } 现在我们来说明它具有的几个特征：
（1) 空链接的颜色为黑色，这也说明根结点中的颜色标记为黑色，因为指向根节点的链接是空链接；
（2）红链接全是左链接；
（3）没有任何一个结点同时和两条红链接相连，因为如果将2-3树的3-结点画成红色左链接相连的两个2-结点，必然不会存在能够和两条红色链接相连的结点；
（4）任意空链接到根结点的路径上的黑链接数量相同，该树完美黑色平衡。
要使这棵树完美黑色平衡，以上条件必须满足。如果不满足，就必须进行调整，调整的策略就是对树进行旋转和颜色转换。</description>
    </item>
    
    <item>
      <title>KMP Algorithm | KMP算法</title>
      <link>https://root-zr.github.io/en/2021/07/23/kmp-algorithm-kmp%E7%AE%97%E6%B3%95/</link>
      <pubDate>Fri, 23 Jul 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/07/23/kmp-algorithm-kmp%E7%AE%97%E6%B3%95/</guid>
      <description>背景 KMP算法是用来解决字符串的匹配问题的。对于字符串匹配问题，我们首先想到的就是暴力破解法。
用指针i,j来说明，第一个位置下标以0开始。如果匹配则继续比较下一位。否则将j的值清0，i的值也要回到最开始匹配成功的位置重新开始比较，如下图。
public int strStr(String haystack, String needle) { if (needle == &amp;#34;&amp;#34;) { return 0; } for (int i = 0; i &amp;lt; haystack.length() - needle.length() + 1; i++) { for (int j = 0; j &amp;lt; needle.length(); j++) { if (needle.charAt(j) != haystack.charAt(j + i)) { break; } if (j == needle.length() - 1) { return i; } } } return -1; } 暴力算法有一个很严重的问题就是一旦不匹配就要从目标字符串的第一个字符开始从头计算。如果是人为来寻找的话，我们肯定不会这样做，因为主串匹配失败的位置(i=3)前面除了第一个A之外再也没有A了，我们为什么能知道主串前面只有一个A？因为我们已经知道前面三个字符都是匹配的[1] 。换句话说是我们知道匹配失败位置之前的元素都不是A，所以我们可以直接将i指针移动到下图所示的位置：
这样就避免了回退的问题，其实前面的例子中要匹配的字符串（ABCE）中并没有出现相同的字符，所以多少会有一点巧合的意思。现在我们用另外一个例子来说明。假设文档的字符串source = &amp;ldquo;abaabaabca&amp;rdquo;, 目标字符串target = &amp;ldquo;abaabca&amp;rdquo;</description>
    </item>
    
    <item>
      <title>deploy mysql on ubuntu OS | ubuntu配置mysql数据库</title>
      <link>https://root-zr.github.io/en/2021/06/19/deploy-mysql-on-ubuntu-os-ubuntu%E9%85%8D%E7%BD%AEmysql%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
      <pubDate>Sat, 19 Jun 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/06/19/deploy-mysql-on-ubuntu-os-ubuntu%E9%85%8D%E7%BD%AEmysql%E6%95%B0%E6%8D%AE%E5%BA%93/</guid>
      <description>使用的ubuntu版本为18.04，mysql的版本为5.7
下载MySQL 首先使用linux命令下载到本地：
wget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.25-linux-glibc2.12-x86_64.tar.gz 然后解压缩
tar -xvf mysql-5.7.25-linux-glibc2.12-x86_64.tar.gz 注意：为了方便，之后的命令一律采用root账户来配置
移动到/usr/local/并且将mysql-5.7.25-linux-glibc2.12-x86_64重命名为mysql
mv mysql-5.7.25-linux-glibc2.12-x86_64 /usr/local/mysql 创建mysql用户组和用户并修改权限 groupadd mysql useradd -r -g mysql mysql 创建数据目录并赋予权限
mkdir -p /data/mysql #创建目录 chown mysql:mysql -R /data/mysql #赋予权限 配置my.cnf文件，用以下命令打开
vim /etc/my.cnf 文件的内容如下[1] ：
[mysqld] bind-address=0.0.0.0 port=3306 user=mysql basedir=/usr/local/mysql datadir=/data/mysql socket=/tmp/mysql.sock log-error=/data/mysql/mysql.err pid-file=/data/mysql/mysql.pid #character config character_set_server=utf8mb4 symbolic-links=0 explicit_defaults_for_timestamp=true 其中bind-address=0.0.0.0是设置允许远程连接，port=3306表示端口号为3306.
完成上面的步骤之后我们就可以进行数据库的初始化工作了，首先进入mysql的bin目录
cd /usr/local/mysql/bin/ 然后执行bin目录下的mysqld脚本，用来初始化信息，
./mysqld --defaults-file=/etc/my.cnf --basedir=/usr/local/mysql/ --datadir=/data/mysql/ --user=mysql --initialize 这里的user=mysql其实不重要，后续可以设置成root
但是很不幸它报错了，错误信息是./mysqld: error while loading shared libraries: libaio.so.1: cannot open shared object file。其实原因是我们没有下载libaio这个安装包，那我们就下载一个呗，命令如下：</description>
    </item>
    
    <item>
      <title>Error: &#39;DT_ Dir&#39; not declared (first used in this function) | ‘DT_DIR’未声明(在此函数内第一次使用) 解决办法</title>
      <link>https://root-zr.github.io/en/2021/06/17/error-dt_-dir-not-declared-first-used-in-this-function-dt_dir%E6%9C%AA%E5%A3%B0%E6%98%8E%E5%9C%A8%E6%AD%A4%E5%87%BD%E6%95%B0%E5%86%85%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%BD%BF%E7%94%A8-%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</link>
      <pubDate>Thu, 17 Jun 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/06/17/error-dt_-dir-not-declared-first-used-in-this-function-dt_dir%E6%9C%AA%E5%A3%B0%E6%98%8E%E5%9C%A8%E6%AD%A4%E5%87%BD%E6%95%B0%E5%86%85%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%BD%BF%E7%94%A8-%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</guid>
      <description>在编写Linux系统下执行的C语言文件时报错
错误：‘DT_DIR’未声明(在此函数内第一次使用)
解决办法： 需要事先导入对应的依赖
#include &amp;lt;sys/types.h&amp;gt;#include &amp;lt;dirent.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;errno.h&amp;gt;然后在编译的时候加上 -D_BSD_SOURCE[1] ，即只需要在我上面的指令基础上变成
gcc difftree.c -lpthread -D_BSD_SOURCE -o difftree.sh --std=c99 然后就能成功编译了
上面指令的-lpthread是因为使用的编译器版本的for循环不支持将int型变量定义在括号内的情况，需要指定编译器的版本才能成功进行编译。这里选择的是最新的编译器版本C99。
参考  ^ https://www.it1352.com/369511.html  </description>
    </item>
    
    <item>
      <title>The Non-recursion Algorithmic of Merging Sort and QuickSort|快速排序和归并排序的非递归实现</title>
      <link>https://root-zr.github.io/en/2021/05/07/the-non-recursion-algorithmic-of-merging-sort-and-quicksort%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E5%92%8C%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E7%9A%84%E9%9D%9E%E9%80%92%E5%BD%92%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Fri, 07 May 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/05/07/the-non-recursion-algorithmic-of-merging-sort-and-quicksort%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E5%92%8C%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E7%9A%84%E9%9D%9E%E9%80%92%E5%BD%92%E5%AE%9E%E7%8E%B0/</guid>
      <description>目前网络上和教材种对这两种排序算法大多是采用递归的方式来实现的，但是非递归的方式较少。另外这两种排序算法也各有特点，像是一对孪生兄弟。首先快排是先排序后分块，归并是先分块后排序，这点在递归方式实现中体现地尤为明显；同时快排是不稳定的排序，归并是稳定的排序；快排不需要额外的内存空间，而归并需要一个和输入数组相同的内存空间。
快速排序的非递归实现 如上所述，快排是要先把一个元素排到对应的位置然后再分块，这个很容易用栈来实现，同时在遇到将递归转为非递归的问题的时候，我们可以首先思考用栈能否实现。具体代码如下：
public static int[] QuickSort(int[] arr, int left, int right) { Stack&amp;lt;Integer&amp;gt; stack = new Stack&amp;lt;&amp;gt;(); if (left &amp;lt; right) { stack.push(left); stack.push(right); while (!stack.isEmpty()) { int height = stack.pop(); int low = stack.pop(); int index = partition(arr, low, height); if (index - 1 &amp;gt; low) { stack.push(low); stack.push(index - 1); } if (index + 1 &amp;lt; height) { stack.push(index + 1); stack.push(height); } } } return arr; } private static int partition(int[] list, int first, int last) { int pivot = list[first]; int low = first + 1; int high = last; while (high &amp;gt; low) { while (low &amp;lt;= high &amp;amp;&amp;amp; list[low] &amp;lt;= pivot) low++; while (low &amp;lt;= high &amp;amp;&amp;amp; list[high] &amp;gt; pivot) high--; if (high &amp;gt; low) { int temp = list[high]; list[high] = list[low]; list[low] = temp; } } while (high &amp;gt; first &amp;amp;&amp;amp; list[high] &amp;gt;= pivot) high--; if (pivot &amp;gt; list[high]) { list[first] = list[high]; list[high] = pivot; return high; } else { return first; } } 归并排序的非递归实现 归并不同于快排，它要求首先把整个数组分成最小的块，每个块是有序的，然后再逐层往上排序。这样就使得没法用栈来实现。具体的代码如下：</description>
    </item>
    
    <item>
      <title>Linux create process and thread instance | Linux创建进程，线程实例</title>
      <link>https://root-zr.github.io/en/2021/04/22/linux-create-process-and-thread-instance-linux%E5%88%9B%E5%BB%BA%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E5%AE%9E%E4%BE%8B/</link>
      <pubDate>Thu, 22 Apr 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/04/22/linux-create-process-and-thread-instance-linux%E5%88%9B%E5%BB%BA%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E5%AE%9E%E4%BE%8B/</guid>
      <description>环境准备  本文采用的操作系统是CentOS7 需要事先安装好gcc和g++环境，分别用来编译c和c++代码  安装命令如下[1] ：
# 安装gcc yum install gcc #安装 g++ yum install gcc-c++ 这里yum为centos的安装命令，Ubuntu的安装命令为apt-get。
进程实例 1.实例描述
首先在linux下编写一个应用程序，命名为an_ch2_1b。这个程序不断地输出如下行：
Those output come from child,[系统时间] 另外写一个应用程序，命名为an_ch2_1a。这个程序创建一个子进程，执行an_ch2_1b。
2.具体步骤
首先创建一个索引目录exer用来存放脚本代码，然后转到exer目录下，使用指令
cat &amp;gt; an_ch2_1b.cpp &amp;lt;&amp;lt; EOF 来创建C++脚本文件，EOF表示在文件中输入EOF退出。
输入an_ch2_1b.cpp的代码如下：
#include &amp;lt;iostream&amp;gt;#include &amp;lt;string&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;#include &amp;lt;time.h&amp;gt;using namespace std; string getTime() // 获取系统时间 { time_t timep; time(&amp;amp;timep); char tmp[64]; strftime(tmp, sizeof (tmp), &amp;#34;%Y-%m-%d%H:%M:%S&amp;#34; ,localtime(&amp;amp;timep)); return tmp; } int main() { while ( true ) { string tmn = getTime(); cout &amp;lt;&amp;lt; &amp;#34;Those output come from child,&amp;#34; &amp;lt;&amp;lt; tmn &amp;lt;&amp;lt; endl; sleep(1); // 为了便于截屏使用sleep() 函数延迟输出  } return 0; } 编写完成之后就需要对源代码进行编译，输入如下指令进行编译</description>
    </item>
    
    <item>
      <title>Xshell remote connect to ubuntu | Xshell远程连接ubuntu</title>
      <link>https://root-zr.github.io/en/2021/03/23/xshell-remote-connect-to-ubuntu-xshell%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5ubuntu/</link>
      <pubDate>Tue, 23 Mar 2021 01:53:34 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2021/03/23/xshell-remote-connect-to-ubuntu-xshell%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5ubuntu/</guid>
      <description>本文采用的版本是Xshell7和ubuntu18.04，默认是刚安装ubuntu操作系统时的情况。
获取主机IP 首先打开Xshell，新建会话
这里名称可以随便起，然后就需要知道要连接主机的ip，同时连接的协议是SSH，首先解决主机IP的问题，打开ubuntu的终端，输入ifconfig，结果发现出现了
我们按照提示输入指令
sudo apt install net-tools 这里的sudo是用管理员权限，所以可能需要输入密码，然后可能会出现以下情况，显示资源暂时不可用，如果没有这种情况可以忽略解决这个问题的部分，继续进行下面的步骤：
这时需要用管理员权限把上面提示的目录删掉，删除命令就是rm
sudo rm /var/lib/dpkg/lock 这时执行sudo apt install net-tools就能成功安装了，然后执行指令ifconfig就可以看到对应的ip了。
安装SSH服务 然后解决SSH的问题，因为系统里可能没有SSH服务，所以同样需要重新安装，然后启动SSH服务，查看状态是否正常，如果状态正常就可以继续进行远程连接了，具体安装SSH服务可以参考下面的博客：
ubuntu远程连接_ANDY-CSDN博客_ubuntu远程连接blog.csdn.net/qq_34510308/article/details/101433987 看到如下界面表示连接成功
另外在远程连接过程中需要输入用户名和密码，这里对应的就是ubuntu的系统用户名以及密码。</description>
    </item>
    
  </channel>
</rss>
