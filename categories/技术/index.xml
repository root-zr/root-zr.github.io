<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>技术 on Albert Wang</title>
    <link>https://root-zr.github.io/categories/%E6%8A%80%E6%9C%AF/</link>
    <description>Recent content in 技术 on Albert Wang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Apr 2022 13:39:37 +0800</lastBuildDate><atom:link href="https://root-zr.github.io/categories/%E6%8A%80%E6%9C%AF/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Distributed System and MapReduce | 分布式系统和MapReduce</title>
      <link>https://root-zr.github.io/en/2022/04/20/distributed-system-and-mapreduce-%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%92%8Cmapreduce/</link>
      <pubDate>Wed, 20 Apr 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/04/20/distributed-system-and-mapreduce-%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%92%8Cmapreduce/</guid>
      <description>这篇博客主要是学习MIT的公开课6.824分布式系统 的学习笔记，在课程一开始老师主要介绍了分布式系统的和MapReduce的基本概念，后续有关于实现一个具体的MapReduce的实验。
分布式系统的基本概念 首先当用户要访问信息的时候，一般需要一个WEB的网页接口去和后台的数据库操作。当用户量很大的时候一台机器就不足以支撑这么大的并发量了，同时数据库所在的服务器也有可能会出现问题。所以很自然的想法就是用多台机器来分担压力。如果足够理想，两台机器就可以把压力减小一般，一直这样下去……不过可惜的是现实中这是不可能的。
现在想法是有了，但是怎样去实现它呢？我们知道一台机器是不容易出现问题的，一台电脑是可以陪伴我们很多年的。但是在一个具有成千上万台机器的分布式集群中出现问题确实非常常见的事，所以人们只能尽可能保证容错，而容错机制主要包括下面三个特性：
 可用性（Availability）：我们要能用这个系统，但是它又时常会出问题，那我们只能定期去把数据备份起来了，所以备份可以保证这个系统是可用的； 可恢复性（Recoverability)：我们已经备份了数据，那就要保证在出问题的时候能恢复到出错前的状态。这里可用的一些操作就是更新日志，设置一些检查点，使用非易失性的存储介质（如硬盘），不能一不小心停电了然后什么都没了。 一致性（Consistency)：我们现在有了备份，那多个副本中的数据是不是能保证一致呢？比如在一个&amp;lt;key,value&amp;gt;的数据库中，张三要取1000元钱，然后发送请求导致主数据库更新了数据，但是就在发送更新副本的时候网断了，这就导致了数据的不一致。  而且就备份来说，它应该距离主体非常远，如果两台机器共用一个电源然后断电了或者该地发生了不可预见的地震，后果都是难以承受的。另外分布式系统作为一个基础设施，它有三个很重要的组成，就是存储系统，通信系统和计算系统。
MapReduce MapReduce是谷歌大数据三驾马车中的其中一篇论文，它被提出的目的是用来解决海量网页数据索引和排序之类的问题。它包含Map和Reduce两个过程，以WordCount为例，它的计算过程如下图所示：
当我们面临着一个大文件的时候，谷歌的文件系统GFS(Google File System)会把它差分成多个64kb的块，用来做任务分配的master服务器知道它们具体在哪台机器上，然后它会指定work machine去执行Map的操作。加入这些文件块的存放位置和work machine不是同一台机器，那就需要通过网络通信来进行数据交换，可是这样会导致效率下降，所以一般都会将它们放在同一台机器上，work machine只需要做一个文件读取的操作就可以了。Map(k,v)的v指的就是某一个块的全部文字，所以下面只需要将单词拆分开然后变成key,1的形式就可以了。
Inuput: Map(k,v) split v into words for each word emit(w,&amp;quot;1&amp;quot;) 在整个Map的过程中master是不需要去一致盯着每台机器去做运算的，每个work machine会将自己运算的中间结果保存在自己的本地磁盘上。以上图中的INPUT 1为例，它最终会保存（a,1)和(b,1)两个值。
然后是Reduce的过程，MapReduce worker通过网络收集所有完成了map worker中&amp;lt;key(i), 1&amp;gt;的任务task，从存储在各个Map worker磁盘上收集数据。这里并不要求每一个Map的所有任务都完成，如果只请求(a,1)这个Map过程，只要work machine完成了这一个任务，就可以将结果返回，不用等全部工作完成。Reduce的伪代码可以表示如下：
Inuput: Reduce(k,v) emit(len(v)) 它的实现相对简单一点，只是对这些收集到的信息做一个加总的操作，计算出长度就行了。</description>
    </item>
    
    <item>
      <title>Source Code Analysis of qsort Function in C Language| C语言qsort源码分析</title>
      <link>https://root-zr.github.io/en/2022/04/10/source-code-analysis-of-qsort-function-in-c-language-c%E8%AF%AD%E8%A8%80qsort%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</link>
      <pubDate>Sun, 10 Apr 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/04/10/source-code-analysis-of-qsort-function-in-c-language-c%E8%AF%AD%E8%A8%80qsort%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</guid>
      <description>在阅读这篇博客之前请确保您已经理解了快速排序的思想。
qsort函数位于GLIBC的stdlib目录下，内部实现了快速排序的功能，我们先不去管这个函数内部具体是怎么实现的，先来考虑如果我们要调用它，该怎么去调用呢。很显然，我们需要给它传入一个待排序的数组array，由于C语言会将数组参数转为指针，所以很自然地要传入一个数组长度的值，一般表示数组长度就是arraySize。看起来没什么问题，那我们来看一下它对外封装的接口是不是如我们所想呢。
看来我们的考虑还是欠佳，封装的接口有四个参数，除了传入的数组以外还要传入数组个数，每个元素的大小和一个比较函数。比较函数还是很容易理解的，因为我们毕竟不能保证始终要求它给我们升序排列，也不能保证随便什么内容都要求程序可以不出错的给我们排好序。但是为什么传入数组大小的时候必须要分开传参呢，我们自己写函数的时候也是只传了一个参数表示数组长度的呀。在分析原因之前我们先按照提供的接口简单测试一个例子吧。
#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt; int Cmp(const void * a, const void * b) { return ( *(int*)a - *(int*)b ); } int main() { int n; int values[] = { 2, 5, 4, 1, 3 }; printf(&amp;#34;排序之前的列表：\n&amp;#34;); for( n = 0 ; n &amp;lt; 5; n++ ) { printf(&amp;#34;%d &amp;#34;, values[n]); } qsort(values, 5, sizeof(int), Cmp); printf(&amp;#34;\n排序之后的列表：\n&amp;#34;); for( n = 0 ; n &amp;lt; 5; n++ ) { printf(&amp;#34;%d &amp;#34;, values[n]); } return(0); } 排序的结果如下图，</description>
    </item>
    
    <item>
      <title>A Method Convert Latex to Word| 一个将latex公式转换为word公式的小窍门</title>
      <link>https://root-zr.github.io/en/2022/03/23/a-method-convert-latex-to-word-%E4%B8%80%E4%B8%AA%E5%B0%86latex%E5%85%AC%E5%BC%8F%E8%BD%AC%E6%8D%A2%E4%B8%BAword%E5%85%AC%E5%BC%8F%E7%9A%84%E5%B0%8F%E7%AA%8D%E9%97%A8/</link>
      <pubDate>Wed, 23 Mar 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/03/23/a-method-convert-latex-to-word-%E4%B8%80%E4%B8%AA%E5%B0%86latex%E5%85%AC%E5%BC%8F%E8%BD%AC%E6%8D%A2%E4%B8%BAword%E5%85%AC%E5%BC%8F%E7%9A%84%E5%B0%8F%E7%AA%8D%E9%97%A8/</guid>
      <description>今天在看IEEE网页上的论文的时候发现它的公式竟然可以被复制成多种格式.
欣喜至于便去了解了一下这种技巧。然后发现其实是因为它的网页中引入了MathJax.js脚本。
&amp;lt;script type=&amp;#34;text/javascript&amp;#34; src=&amp;#34;/xploreAssets/MathJax-274/MathJax.js?config=default&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; 同样的道理，我们也可以按照这种方式来编写latex公式，然后通过浏览器解析之后再将它复制成word对应的代码文本。道理很简单，那么具体该怎么做呢？
首先我们就需要一个.html的文件了，因为是要浏览器来解析的。然后将脚本导入进来。可以看到整个页面中基本只引入了MathJax的脚本，不需要别的什么设置。然后把我们需要的公式用latex的方式写在里。
&amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;script type=&amp;#34;text/javascript&amp;#34; src=&amp;#34;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&amp;#34;&amp;gt; &amp;lt;/script&amp;gt; &amp;lt;title&amp;gt;tex to word&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; \begin{equation*} q_{j}=W\cdot\vec{x}_{j:j+R-1}+\vec{b} \tag{1} \end{equation*} &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; 然后通过浏览器打开，鼠标右键将其保存为MathML code，如下图所示：
然后在word中选择插入公式，将拷贝出来的文本以纯文本的形式粘贴到公式块中就完成了。如果要转换不同的公式只需要在上面的标签中不断添加公式就可以了。
不过还是可以看到一个小缺陷，我们在tex格式里是加了\tag{1}的，而且网页也能显示，但是粘贴到word里就没有了。所以只能用word的方式来插入，选择插入——&amp;gt;文档部件，选择域，如下图：
然后在公式编辑区域里输入#(数字)，按下回车就可以成功编号了。
参考资料：
https://tex.stackexchange.com/questions/25223/embed-latex-math-equations-into-microsoft-word</description>
    </item>
    
  </channel>
</rss>
