<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>技术 on Albert Wang</title>
    <link>https://root-zr.github.io/categories/%E6%8A%80%E6%9C%AF/</link>
    <description>Recent content in 技术 on Albert Wang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Feb 2025 13:39:37 +0800</lastBuildDate><atom:link href="https://root-zr.github.io/categories/%E6%8A%80%E6%9C%AF/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Disaggregated Memory | 云计算之分解内存系统</title>
      <link>https://root-zr.github.io/en/2025/02/03/disaggregated-memory-%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B9%8B%E5%88%86%E8%A7%A3%E5%86%85%E5%AD%98%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Mon, 03 Feb 2025 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2025/02/03/disaggregated-memory-%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B9%8B%E5%88%86%E8%A7%A3%E5%86%85%E5%AD%98%E7%B3%BB%E7%BB%9F/</guid>
      <description>这篇博客主要介绍云计算中的分解内存系统。在分解内存系统中，计算节点和内存节点分别负责计算和存储。
分解内存系统 内存缓存系统是云服务的核心组件。然而，由于传统单体服务器中CPU与内存的紧耦合，现有缓存系统无法以资源高效且敏捷的方式弹性调整资源。为实现更好的弹性，人们将内存缓存系统移植到分解内存系统（Disaggregated Memory, DM）架构中，该架构将计算与内存资源解耦并支持灵活分配。分解内存系统将内存、存储和计算资源分离为独立的资源池，以实现高资源利用率、灵活的硬件可扩展性和高效的数据共享。采用支持RDMA的网络进行通信，RDMA具有高吞吐量（40-400 Gbps）、低延迟（几微秒）和绕过远程CPU/内核的特点。分解内存系统已成为许多应用的重要基础设施，包括数据库和内存键值（KV）存储。
索引 树结构和学习索引是两种广泛使用的有序KV存储结构，它们通过识别给定范围内的项来提供高效的范围查询性能。
基于树的结构 （例如 B+ 树）将数据存储在叶子节点中，并通过构建多级内部节点来搜索叶子。然而，当数据超出有限的本地缓存时，基于树的结构变得低效，必须进行多次网络往返时间（RTT）来检索内部节点。
学习索引在搜索速度和内存消耗方面相较于基于树的结构具有显著优势，这得益于易于使用且小尺寸的学习模型。具体来说，学习索引将数据搜索过程视为回归模型，通过近似排序键的累积分布函数（CDF）来记录所有数据的位置 。学习模型比树结构的内部节点节省了 2 到 4 个数量级的空间，这使得本地机器能够缓存整个索引结构，避免了多次 RTT 的惩罚，从而确定远程数据的位置。
XStore 提出了一个混合索引结构，即维护一个 B 树来处理修改，并本地缓存学习索引以进行远程数据访问。XStore 提供了高效的搜索性能，因为它仅需要一次 RTT 来访问静态工作负载。对于动态工作负载，XStore 通过在内存节点上修改 B 树来处理数据修改请求。同时，XStore 扩展过时的模型到较大的预测范围，以确保新插入的数据被包含在内。
然而，这种设计在解耦内存系统中变得低效，因为内存节点的计算资源有限，无法高效处理密集的修改请求。新模型未能及时重新训练，且由于模型扩展，过时的模型导致搜索远程数据时的准确性过低，无法在一次 RTT 内完成。因此，本地缓存变得无效，后续的数据请求通过经典的 RPC 转发到内存节点。由于内存节点的计算资源有限，整体性能显著下降。
上图展示了 ROLEX 的总体架构1。在内存池中，ROLEX 将所有数据存储为固定大小的叶节点（即数组），并基于这些数据构建一个与重训练解耦的学习索引。为了处理动态工作负载，计算节点直接修改远程叶节点，而无需重训练模型，因为我们将插入操作和重训练操作解耦。通过添加偏置和一些数据迁移约束，非重训练模型能够在插入新数据后正确识别所有数据。
缓存性能 在DM上构建弹性缓存系统面临两大挑战：
 绕过远程CPU的访问阻碍缓存算法执行：客户端通过远程直接内存访问（RDMA）直接操作数据，导致集中式热度监控失效，且维护缓存数据结构需多次高延迟远程访问。 资源动态调整影响缓存命中率：计算资源（客户端并发数）和内存资源（缓存容量）的变化会改变数据访问模式，使得固定缓存算法难以适应动态场景。  Ditto采用分布式自适应缓存策略，通过实时评估多个缓存算法的性能，动态切换至最佳适配算法以提升缓存命中率2。
上图展示了 Ditto 的整体架构。Ditto 采用哈希表组织内存池中存储的对象。该哈希表保存指向缓存对象地址的指针。遵循现有DM存储系统架构，应用程序运行于计算节点，每个应用程序通过本地子进程托管一个Ditto客户端。每个Ditto客户端在专用核心上运行多线程，应用程序通过本地共享内存与Ditto客户端通信，执行Get和Set操作。在此架构下，应用程序可通过增减分配给Ditto的线程数和CPU核心数自由扩缩计算资源。由于增减CPU核心时无需调整内存池的缓存容量，计算资源调整与缓存数据完全解耦。
Ditto通过两大核心机制实现DM上的缓存淘汰：
 以客户端为中心的缓存框架：通过为不同缓存算法生成多组淘汰候选，高效执行多种算法。 分布式自适应缓存策略：利用机器学习分析当前数据访问模式特征，选择性能最优的算法淘汰候选。    https://www.usenix.org/conference/fast23/presentation/li-pengfei&amp;#160;&amp;#x21a9;&amp;#xfe0e;
 Jiacheng Shen, Pengfei Zuo, Xuchuan Luo, Yuxin Su, Jiazhen Gu, Hao Feng, Yangfan Zhou, Michael Lyu, “Ditto: An Elastic and Adaptive Memory-Disaggregated Caching System”, Proceedings of the 29th ACM Symposium on Operating Systems Principles (SOSP), 2023.</description>
    </item>
    
    <item>
      <title>Elastic Block Storage | 云计算之块存储</title>
      <link>https://root-zr.github.io/en/2024/10/05/elastic-block-storage-%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B9%8B%E5%9D%97%E5%AD%98%E5%82%A8/</link>
      <pubDate>Sat, 05 Oct 2024 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2024/10/05/elastic-block-storage-%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B9%8B%E5%9D%97%E5%AD%98%E5%82%A8/</guid>
      <description>这篇博客主要从阿里巴巴的论文 “What&amp;rsquo;s the Story in EBS Glory: Evolutions and Lessons in Building Cloud Block Store” 来介绍云块存储。详细的内容可以参考 Fast2024 主页的演讲1。如果存在网络问题也可以从我本地连接下载，论文原文点击这里 ，PPT点击这里 。
阿里巴巴的云块存储从开始发展至今已经经过了多次迭代，从下面的时间线可以看出距离 2012 年的 EBS1 开始已经发展到了 EBSX 的版本。
BES1 在云计算的 IaaS 中，云厂商可以把计算资源和存储资源这些基础设施抽象成服务，对外以虚拟机的方式出售。云计算的客户只会感知到虚拟机提供的资源，但是在云计算厂商内部，虚拟机内的资源可以映射到不同的物理机上。计算和存储分离就是其中一种设计，通过将计算资源和存储资源放在不同的集群中，集群中间通过数据中心网络连接。这些设计也在微软的 Azure 和 Google 的数据中心中被采用。
块存储对外提供的是一种虚拟磁盘（Virtual Disk，VD），一台虚拟机可以挂载多个 VD。到目前我们云计算客户如果要使用存储资源，他们可以先购买不同容量的 VD，然后把 VD 挂载到自己的虚拟机中。事实上 EBS1 的设计也是如此，下图中计算集群中的 1 个 BlockClient 可以负责多个 VM，它们负责将 IO 请求转发到存储集群的 BlockServer 中。
BlockServer 本身是无状态的，这就需要构建 BlockManager 集群来管理 VD 的元数据，包括容量，快照版本等等。另外 VD 的逻辑块地址（LBA）被划分成一个个 64M 的块（chunk）。ChunkServer 就是用来处理这一个个的 chunk。同样地，也需要有 ChunkManager 来管理 chunk 的元数据。
这时一个 IO 从计算集群的 VM 发过来，BlockClient 会先从 BlockManager 找到该 IO 应该发给哪个 BlockServer ，收到 ACK 之后发到对应的 BlockServer，然后 BlockServer 从 ChunkManager 查到该请求应该发给哪个 ChunkServer ，最后在一层层返回 ACK 给 BlockClient，这样就完成了一次 IO。</description>
    </item>
    
    <item>
      <title>Union-Find Disjoint Sets | 并查集</title>
      <link>https://root-zr.github.io/en/2022/12/10/union-find-disjoint-sets-%E5%B9%B6%E6%9F%A5%E9%9B%86/</link>
      <pubDate>Sat, 10 Dec 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/12/10/union-find-disjoint-sets-%E5%B9%B6%E6%9F%A5%E9%9B%86/</guid>
      <description>算法介绍 并查集主要用于集合之间的操作。对于两个集合而言，它们一般能做的就是将两个集合的元素合并（并）。同时，我们往往会希望知道两个元素在不在同一个集合中（查）。由此便引出了并查集这种数据结构。
为了便于理解，我们先将问题进行简化。假如目前摆在我们面前的有这样一个图
在这个图中 每两个节点之间的连通关系和它们之间的距离可以用如下的二维数组来表示，
[[1,2,9],[2,3,6],[2,4,5],[1,4,7]] 我们现在希望找到一种数据结构，从我们给定的联通关系中从 0 构建上面的那张图，并且可以高效地实现查找某一个节点在不在这张连通图里面。所以我们可以将它们用一个一维数组的方式来存储，如下图所示
我们将数组的下标用来表示元素节点，用数组下标对应的值来表示它们的父亲节点，这样就可以构建一个father数组。我们在初始化的时候可以将它们的父亲节点都初始化成自己，这时对应的图就是每个节点各自都不连通，然后我们在用并查集的并来对这个数组进行赋值（这时我们不妨先假设father数组已经构建好了）。
public int findFather(int n) { if (fa[n] == n) { return n; } return findFather(fa[n]); } public void unionSet(int i, int j) { int faI = findFather(i); int faJ = findFather(j); if (faI != faJ) { fa[faJ] = faI; } } 我们首先来观察 findFather 这个函数，这个函数做的事情就是找一个节点的根节点。如果一个节点的父结点就是它自己的话说明我们已经找到这棵树的根了，然后就返回这个节点的 id。否则，我们就找这个节点父结点的父结点，也就是它的“爷爷节点”，逐层向上递归，最终我们一定能找到这个节点所在集合的根节点，并且保证时间复杂度是线性的。
然后我们再来观察 unionSet 这个函数，这个函数首先会去找两个元素i，j 的根节点，如果它们的根节点是一样的，说明它们在一个集合里，这里我们不进行操作；否则，说明它们在不同的集合，这时我们要做的操作就是把这两个集合合并起来，我们只需要让其中一个根节点的父结点变成另一个节点就可以了。这样我们就完成了两个集合的合并操作。
到这里并查集的任务基本已经完成了，我们来思考一下有没有什么可以进一步优化的空间。手下来看 findFather 这个函数，我们显然可以知道它的时间复杂度是线性的。也就是说，如果我们的运气足够差，当我们目前构建的这个树退化成了单向链表，在时间上我们就要付出更大的成本了。所以可以考虑有一种优化的方式，因为我们在调用这个函数的时候只想知道根节点是谁，并不一定要记录每个节点的父结点，所以我们可以在初始化的时候将每个节点的父结点都设置为根节点，代码表示如下
public int findFather(int n) { if (fa[n] == n) { return n; } return fa[n] = findFather(fa[n]); } 这段代码需要说明的一点是 fa[n] = findFather(fa[n]) 这个表达式本身是有返回值的，返回值是 fa[n] 最终被赋予的那个值。</description>
    </item>
    
    <item>
      <title>A Slide for Zookeeper Learning | zookeeper学习中的PPT分享</title>
      <link>https://root-zr.github.io/en/2022/07/07/a-slide-for-zookeeper-learning-zookeeper%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84ppt%E5%88%86%E4%BA%AB/</link>
      <pubDate>Thu, 07 Jul 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/07/07/a-slide-for-zookeeper-learning-zookeeper%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84ppt%E5%88%86%E4%BA%AB/</guid>
      <description>这是一篇用来测试共享文件的博客，分享了一篇关于 zookeeper 分布式组件学习的PPT。
在PPT制作过程中参考了尚硅谷的教学材料【尚硅谷】大数据技术之Zookeeper 3.5.7版本教程_哔哩哔哩_bilibili 和 Raft 以及 zookeeper 的论文原文。
PPT 采用zoho 来托管，您可以点击这里 获取到PPT原文
 您也可以通过鼠标右键下面的内容，另存为pdf版本的文件。</description>
    </item>
    
    <item>
      <title>Distributed System and MapReduce 02 | 分布式系统和MapReduce 02</title>
      <link>https://root-zr.github.io/en/2022/06/15/distributed-system-and-mapreduce-02-%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%92%8Cmapreduce-02/</link>
      <pubDate>Wed, 15 Jun 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/06/15/distributed-system-and-mapreduce-02-%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%92%8Cmapreduce-02/</guid>
      <description>这篇博客主要是关于 MIT 的公开课 6.824 分布式系统 的 lab 1相关内容，lab 1 要求我们实现一个分布式的mapreduce系统，并且已经为我们提供了一些基础的代码，lab 的地址请点击这里 。下面让我们从文件的架构开始一点点去了解我们所要做的事情。下面是一个精简了的代码结构图，它可以帮助我们理解 lab 1的内容。
单机mapreduce任务 首先我们需要明确的是main目录下的文件是我们的程序入口处， 如果我们执行mrsequential.go 文件将会启动一个单机的mapreduce任务，执行的命令如下
go run -race mrsequential.go wc.so pg*.txt 可以看到在执行的时候还传了两个参数，这两个参数的作用是什么呢？我们从代码中来观察一下，
if len(os.Args) &amp;lt; 3 { fmt.Fprintf(os.Stderr, &amp;quot;Usage: mrsequential xxx.so inputfiles...\n&amp;quot;) os.Exit(1) } mapf, reducef := loadPlugin(os.Args[1]) 可以看到 wc.so 是用来加载 map 和 reduce 函数的， 而 wc.so 文件则是由下面这个命令生成的，通过-buildmode=plugin可以以插件的形式将wc.go 文件里的函数封装起来，然后通过loadPlugin 函数重新加载出来。
 go build -race -buildmode=plugin ../mrapps/wc.go loadPlugin 函数是作者自己编写的，具体是封装了plugin.Open 和 p.Lookup两个函数的功能，最终的结果是获取到map 和 reduce 两个函数。
func loadPlugin(filename string) (func(string, string) []mr.</description>
    </item>
    
    <item>
      <title> From Maximum Convention Number to Cryptography| 从最大公约数到密码学</title>
      <link>https://root-zr.github.io/en/2022/05/12/from-maximum-convention-number-to-cryptography-%E4%BB%8E%E6%9C%80%E5%A4%A7%E5%85%AC%E7%BA%A6%E6%95%B0%E5%88%B0%E5%AF%86%E7%A0%81%E5%AD%A6/</link>
      <pubDate>Thu, 12 May 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/05/12/from-maximum-convention-number-to-cryptography-%E4%BB%8E%E6%9C%80%E5%A4%A7%E5%85%AC%E7%BA%A6%E6%95%B0%E5%88%B0%E5%AF%86%E7%A0%81%E5%AD%A6/</guid>
      <description>这篇博客主要从我们小学时了解的最大公约数概念出发，一步步去了解数之间的关系，最后讲述它们是怎么被应用在密码学当中的。因为篇幅所限，再加上下文中提到的很多相关定理都需要用到离散数学的知识，所以本文中并不涉及到它们的证明，如果您对这些定理的证明感兴趣，请自行查阅相关的书籍。
最大公约数 我们的故事首先从最大公约数讲起，最大公约数是我们非常熟悉的内容了，如果有两个数a和b，存在一个数m，使得m能同时被a和b整除，并且不存在另外比m大且能同时被a和b整除的数，我们就称m是a和b的最大公约数，可以记为 $$ gcd(a,b) = m $$ 这个概念非常明确，如果真的给定了两个数，要去求它的最大公约数，我们也能很显然地相除一种暴力的解法。那就是让i从1到min(a,b)开始不断去判断是否满足同时被a和b整除，满足条件的最大值就是最大公约数。这种做法的时间复杂度也是很显然的，它是O(min(a/2,b/2))。这种做法在a，b都很大的时候显然不是一个值得提倡的做法，所以人们也想了很多办法去优化它，欧几里得算法就是一个很好的优化方案。
我们不妨假设a &amp;gt; b，则a一定可以表示为下面这种形式 $$ a = p \times b + r $$ 其中p表示a除以b的商，r表示余数。同样的b可以表示为 $$ b = q \times r + r_2 $$ 其中q表示b除以r的商，$r_2$表示余数。如此往复，最终我们将会得到余数$r_i$为0的情况，这时它上面的余数就是a和b的最大公约数。我们可以从一个简单的例子来看这个算法，加入a = 64，b = 42，整个过程可以表述为下面的情况。 $$ 64 = 1 \times 42 + 22
$$
$$ 42 = 1 \times 22 + 20
$$
$$ 22 = 1 \times 20 + 2 $$
$$ 20 = 10 \times 2 + 0 $$</description>
    </item>
    
    <item>
      <title>Distributed System and MapReduce 01 | 分布式系统和MapReduce 01</title>
      <link>https://root-zr.github.io/en/2022/04/20/distributed-system-and-mapreduce-01-%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%92%8Cmapreduce-01/</link>
      <pubDate>Wed, 20 Apr 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/04/20/distributed-system-and-mapreduce-01-%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%92%8Cmapreduce-01/</guid>
      <description>这篇博客主要是学习MIT的公开课6.824分布式系统 的学习笔记，在课程一开始老师主要介绍了分布式系统的和MapReduce的基本概念，后续有关于实现一个具体的MapReduce的实验。
分布式系统的基本概念 首先当用户要访问信息的时候，一般需要一个WEB的网页接口去和后台的数据库操作。当用户量很大的时候一台机器就不足以支撑这么大的并发量了，同时数据库所在的服务器也有可能会出现问题。所以很自然的想法就是用多台机器来分担压力。如果足够理想，两台机器就可以把压力减小一般，一直这样下去……不过可惜的是现实中这是不可能的。
现在想法是有了，但是怎样去实现它呢？我们知道一台机器是不容易出现问题的，一台电脑是可以陪伴我们很多年的。但是在一个具有成千上万台机器的分布式集群中出现问题确实非常常见的事，所以人们只能尽可能保证容错，而容错机制主要包括下面三个特性：
 可用性（Availability）：我们要能用这个系统，但是它又时常会出问题，那我们只能定期去把数据备份起来了，所以备份可以保证这个系统是可用的； 可恢复性（Recoverability)：我们已经备份了数据，那就要保证在出问题的时候能恢复到出错前的状态。这里可用的一些操作就是更新日志，设置一些检查点，使用非易失性的存储介质（如硬盘），不能一不小心停电了然后什么都没了。 一致性（Consistency)：我们现在有了备份，那多个副本中的数据是不是能保证一致呢？比如在一个&amp;lt;key,value&amp;gt;的数据库中，张三要取1000元钱，然后发送请求导致主数据库更新了数据，但是就在发送更新副本的时候网断了，这就导致了数据的不一致。  而且就备份来说，它应该距离主体非常远，如果两台机器共用一个电源然后断电了或者该地发生了不可预见的地震，后果都是难以承受的。另外分布式系统作为一个基础设施，它有三个很重要的组成，就是存储系统，通信系统和计算系统。
MapReduce MapReduce是谷歌大数据三驾马车中的其中一篇论文，它被提出的目的是用来解决海量网页数据索引和排序之类的问题。它包含Map和Reduce两个过程，以WordCount为例，它的计算过程如下图所示：
当我们面临着一个大文件的时候，谷歌的文件系统GFS(Google File System)会把它差分成多个64kb的块，用来做任务分配的master服务器知道它们具体在哪台机器上，然后它会指定work machine去执行Map的操作。加入这些文件块的存放位置和work machine不是同一台机器，那就需要通过网络通信来进行数据交换，可是这样会导致效率下降，所以一般都会将它们放在同一台机器上，work machine只需要做一个文件读取的操作就可以了。Map(k,v)的v指的就是某一个块的全部文字，所以下面只需要将单词拆分开然后变成key,1的形式就可以了。
图片来源：Google MapReduce论文
在整个Map的过程中master是不需要去一致盯着每台机器去做运算的，每个work machine会将自己运算的中间结果保存在自己的本地磁盘上。以上图中的INPUT 1为例，它最终会保存（a,1)和(b,1)两个值。
然后是Reduce的过程，MapReduce worker通过网络收集所有完成了map worker中&amp;lt;key(i), 1&amp;gt;的任务task，从存储在各个Map worker磁盘上收集数据。这里并不要求每一个Map的所有任务都完成，如果只请求(a,1)这个Map过程，只要work machine完成了这一个任务，就可以将结果返回，不用等全部工作完成。Reduce的伪代码可以表示如下：
图片来源：Google MapReduce论文
它的实现相对简单一点，只是对这些收集到的信息做一个加总的操作，计算出长度就行了。</description>
    </item>
    
    <item>
      <title>Source Code Analysis of qsort Function in C Language| C语言qsort源码分析</title>
      <link>https://root-zr.github.io/en/2022/04/10/source-code-analysis-of-qsort-function-in-c-language-c%E8%AF%AD%E8%A8%80qsort%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</link>
      <pubDate>Sun, 10 Apr 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/04/10/source-code-analysis-of-qsort-function-in-c-language-c%E8%AF%AD%E8%A8%80qsort%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</guid>
      <description>在阅读这篇博客之前请确保您已经理解了快速排序的思想。
qsort函数位于GLIBC的stdlib目录下，内部实现了快速排序的功能，我们先不去管这个函数内部具体是怎么实现的，先来考虑如果我们要调用它，该怎么去调用呢。很显然，我们需要给它传入一个待排序的数组array，由于C语言会将数组参数转为指针，所以很自然地要传入一个数组长度的值，一般表示数组长度就是arraySize。看起来没什么问题，那我们来看一下它对外封装的接口是不是如我们所想呢。
看来我们的考虑还是欠佳，封装的接口有四个参数，除了传入的数组以外还要传入数组个数，每个元素的大小和一个比较函数。比较函数还是很容易理解的，因为我们毕竟不能保证始终要求它给我们升序排列，也不能保证随便什么内容都要求程序可以不出错的给我们排好序。但是为什么传入数组大小的时候必须要分开传参呢，我们自己写函数的时候也是只传了一个参数表示数组长度的呀。在分析原因之前我们先按照提供的接口简单测试一个例子吧。
#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt; int Cmp(const void * a, const void * b) { return ( *(int*)a - *(int*)b ); } int main() { int n; int values[] = { 2, 5, 4, 1, 3 }; printf(&amp;#34;排序之前的列表：\n&amp;#34;); for( n = 0 ; n &amp;lt; 5; n++ ) { printf(&amp;#34;%d &amp;#34;, values[n]); } qsort(values, 5, sizeof(int), Cmp); printf(&amp;#34;\n排序之后的列表：\n&amp;#34;); for( n = 0 ; n &amp;lt; 5; n++ ) { printf(&amp;#34;%d &amp;#34;, values[n]); } return(0); } 排序的结果如下图，</description>
    </item>
    
    <item>
      <title>A Method Convert Latex to Word| 一个将latex公式转换为word公式的小窍门</title>
      <link>https://root-zr.github.io/en/2022/03/23/a-method-convert-latex-to-word-%E4%B8%80%E4%B8%AA%E5%B0%86latex%E5%85%AC%E5%BC%8F%E8%BD%AC%E6%8D%A2%E4%B8%BAword%E5%85%AC%E5%BC%8F%E7%9A%84%E5%B0%8F%E7%AA%8D%E9%97%A8/</link>
      <pubDate>Wed, 23 Mar 2022 13:39:37 +0800</pubDate>
      
      <guid>https://root-zr.github.io/en/2022/03/23/a-method-convert-latex-to-word-%E4%B8%80%E4%B8%AA%E5%B0%86latex%E5%85%AC%E5%BC%8F%E8%BD%AC%E6%8D%A2%E4%B8%BAword%E5%85%AC%E5%BC%8F%E7%9A%84%E5%B0%8F%E7%AA%8D%E9%97%A8/</guid>
      <description>今天在看IEEE网页上的论文的时候发现它的公式竟然可以被复制成多种格式.
欣喜至于便去了解了一下这种技巧。然后发现其实是因为它的网页中引入了MathJax.js脚本。
&amp;lt;script type=&amp;#34;text/javascript&amp;#34; src=&amp;#34;/xploreAssets/MathJax-274/MathJax.js?config=default&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; 同样的道理，我们也可以按照这种方式来编写latex公式，然后通过浏览器解析之后再将它复制成word对应的代码文本。道理很简单，那么具体该怎么做呢？
首先我们就需要一个.html的文件了，因为是要浏览器来解析的。然后将脚本导入进来。可以看到整个页面中基本只引入了MathJax的脚本，不需要别的什么设置。然后把我们需要的公式用latex的方式写在里。
&amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html&amp;gt; &amp;lt;head&amp;gt; &amp;lt;script type=&amp;#34;text/javascript&amp;#34; src=&amp;#34;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&amp;#34;&amp;gt; &amp;lt;/script&amp;gt; &amp;lt;title&amp;gt;tex to word&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; \begin{equation*} q_{j}=W\cdot\vec{x}_{j:j+R-1}+\vec{b} \tag{1} \end{equation*} &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; 然后通过浏览器打开，鼠标右键将其保存为MathML code，如下图所示：
然后在word中选择插入公式，将拷贝出来的文本以纯文本的形式粘贴到公式块中就完成了。如果要转换不同的公式只需要在上面的标签中不断添加公式就可以了。
不过还是可以看到一个小缺陷，我们在tex格式里是加了\tag{1}的，而且网页也能显示，但是粘贴到word里就没有了。所以只能用word的方式来插入，选择插入——&amp;gt;文档部件，选择域，如下图：
然后在公式编辑区域里输入#(数字)，按下回车就可以成功编号了。
参考资料：
https://tex.stackexchange.com/questions/25223/embed-latex-math-equations-into-microsoft-word</description>
    </item>
    
  </channel>
</rss>
